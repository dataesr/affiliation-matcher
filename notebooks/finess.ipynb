{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime\n",
    "import math\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Q, Search\n",
    "from elasticsearch import helpers\n",
    "import string\n",
    "import json\n",
    "import unicodedata\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prépa du référentiel à partir de finess et dataESR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['Libellé catégorie d’agrégat d’établissement libcategagretab']==\"Centres Hospitaliers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1,2,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('etalab-cs1100502-stock-20200914-0418.csv', \n",
    "            sep=';', encoding=\"iso-8859-1\", skiprows=1, header=None)\n",
    "df.columns = [\"Section : structureet\",\n",
    "\"Numéro FINESS ET nofinesset\",\n",
    "\"Numéro FINESS EJ nofinessej\",\n",
    "\"Raison sociale rs\",\n",
    "\"Raison sociale longue rslongue\",\n",
    "\"Complément de raison sociale complrs\",\n",
    "\"Complément de distribution compldistrib\",\n",
    "\"Numéro de voie numvoie\",\n",
    "\"Type de voie typvoie\",\n",
    "\"Libellé de voie voie\",\n",
    "\"Complément de voie compvoie\",\n",
    "\"Lieu-dit / BP lieuditbp\",\n",
    "\"Code Commune commune\",\n",
    "\"Département departement\",\n",
    "\"Libellé département libdepartement\",\n",
    "\"Ligne d’acheminement (CodePostal+Lib commune) ligneacheminement\",\n",
    "\"Téléphone telephone\",\n",
    "\"Télécopie telecopie\",\n",
    "\"Catégorie d’établissement categetab\",\n",
    "\"Libelle catégorie d’établissement libcategetab\",\n",
    "\"Catégorie d’agrégat d’établissement categagretab\",\n",
    "\"Libellé catégorie d’agrégat d’établissement libcategagretab\",\n",
    "\"Numéro de SIRET siret\",\n",
    "\"Code APE codeape\",\n",
    "\"Code MFT codemft\",\n",
    "\"Libelle MFT libmft\",\n",
    "\"Code SPH codesph\",\n",
    "\"Libelle SPH libsph\",\n",
    "\"Date d’ouverture dateouv\",\n",
    "\"Date d’autorisation dateautor\",\n",
    "\"Date de mise à jour sur la structure datemaj\",\n",
    "\"Numéro éducation nationale numuai\"\n",
    "]\n",
    "\n",
    "\n",
    "df2 = df[df['Libellé catégorie d’agrégat d’établissement libcategagretab'].isin(\n",
    "   [\n",
    "       \"Etab.de soins relevant du service de santé des armées\" ,\n",
    "       \"Centres de Lutte contre le Cancer\",\n",
    "       \"Hôpitaux Locaux\",\n",
    "       \"Centres Hospitaliers Régionaux\",\n",
    "       \"Etablissement de Soins Pluridisciplinaire\"\n",
    "     #  \"Centres Hospitaliers\"\n",
    "   ])\n",
    "  ]\n",
    "\n",
    "df2 = df2[[ 'Numéro FINESS ET nofinesset',\n",
    "           \"Raison sociale rs\",\n",
    "       'Raison sociale longue rslongue',\n",
    "     'Ligne d’acheminement (CodePostal+Lib commune) ligneacheminement',\n",
    "           \"Numéro de voie numvoie\",\n",
    "\"Type de voie typvoie\",\n",
    "\"Libellé de voie voie\",\n",
    "\"Complément de voie compvoie\",\n",
    "\"Lieu-dit / BP lieuditbp\",\n",
    "\"Code Commune commune\",\n",
    "    'Numéro de SIRET siret']].reset_index()\n",
    "del df2['index']\n",
    "#df2.to_csv('/home/jerem/work/matcher/project/server/main/finess.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['Numéro FINESS ET nofinesset'] == \"750000549\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_ORGA = \"http://185.161.45.213/organizations\"\n",
    "def match(siren):\n",
    "\n",
    "    r_post = requests.post(APP_ORGA + \"/organizations/_update\", headers=header, \n",
    "                json = {\"id\": siren})\n",
    "    return r_post.json().get('internal_id')\n",
    "\n",
    "def get(siren):\n",
    "\n",
    "    r = requests.get(APP_ORGA + \"/organizations/\"+siren, headers=header)\n",
    "    return r.json()\n",
    "\n",
    "def update(siren):\n",
    "\n",
    "    r_post = requests.post(APP_ORGA + \"/organizations/_update\", headers=header, \n",
    "                json = {\"id\": siren, \"upsert\": True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(e):\n",
    "    for n in e.get('names', []):\n",
    "        if n.get('status') == 'main':\n",
    "            name_fr = n.get('name_fr')\n",
    "            name_en = n.get('name_en')\n",
    "            if name_fr:\n",
    "                return name_fr\n",
    "            if name_en:\n",
    "                return name_en\n",
    "        \n",
    "    for n in e.get('names', []):\n",
    "        if n.get('status') == 'valid':\n",
    "            name_fr = n.get('name_fr')\n",
    "            name_en = n.get('name_en')\n",
    "            if name_fr:\n",
    "                return name_fr\n",
    "            if name_en:\n",
    "                return name_en\n",
    "        \n",
    "    return None\n",
    "\n",
    "def get_acronym(e):\n",
    "    for n in e.get('acronyms', []):\n",
    "        if n.get('status') == 'main':\n",
    "            name_fr = n.get('acronym_fr')\n",
    "            name_en = n.get('acronym_en')\n",
    "            if name_fr:\n",
    "                return name_fr\n",
    "            if name_en:\n",
    "                return name_en\n",
    "        \n",
    "    for n in e.get('names', []):\n",
    "        if n.get('status') == 'valid':\n",
    "            name_fr = n.get('acronym_fr')\n",
    "            name_en = n.get('acronym_en')\n",
    "            if name_fr:\n",
    "                return name_fr\n",
    "            if name_en:\n",
    "                return name_en\n",
    "        \n",
    "    return None\n",
    "\n",
    "def get_web(e):\n",
    "    for n in e.get('websites', []):\n",
    "        if n.get('status') == 'main':\n",
    "            return n.get('url')\n",
    "        \n",
    "    for n in e.get('names', []):\n",
    "        if n.get('status') == 'valid':\n",
    "            return n.get('url')\n",
    "        \n",
    "    return None\n",
    "\n",
    "def get_address(e):\n",
    "    for n in e.get('addresses', []):\n",
    "        if n.get('status') == 'main':\n",
    "            return n\n",
    "        \n",
    "    for n in e.get('addresses', []):\n",
    "        if n.get('status') == 'valid':\n",
    "            return n\n",
    "        \n",
    "    return {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = {}\n",
    "\n",
    "header = {'Authorization': 'Basic cm9vdDp0b25uZXJyZTJCcmVzdA=='}\n",
    "for i, row in df2.iterrows():\n",
    "    local_id = \"finess{}\".format(row[\"Numéro FINESS ET nofinesset\"])\n",
    "    internal_id = None\n",
    "    siret = None\n",
    "    \n",
    "    if not pd.isnull(row['Numéro de SIRET siret']):\n",
    "        siret = str(row['Numéro de SIRET siret']).replace('.0', '')\n",
    "        local_id = \"siret{}\".format(siret)\n",
    "        internal_id = match(siret)\n",
    "        \n",
    "    if local_id not in my_list:\n",
    "        my_list[local_id] = []\n",
    "        \n",
    "    if internal_id:\n",
    "        dataesr_elt = get(internal_id)\n",
    "        e = {}\n",
    "        e['dataesr_name'] = get_name(dataesr_elt)\n",
    "        e['dataesr_acronym'] = get_acronym(dataesr_elt)\n",
    "        e['dataesr_id'] = internal_id\n",
    "        e['dataesr_website'] = get_web(dataesr_elt)\n",
    "        dataesr_address = get_address(dataesr_elt)\n",
    "        e['dataesr_city'] = dataesr_address.get('city')\n",
    "        e['dataesr_post_code'] = dataesr_address.get('post_code')\n",
    "        e['dataesr_address'] = dataesr_address.get('input_address')\n",
    "        my_list[local_id].append(e)\n",
    "        \n",
    "        \n",
    "    my_list[local_id].append(json.loads(row.to_json()))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "siret26010010200011 1\n",
      "siret26010013600019 1\n",
      "siret26010020100052 1\n",
      "siret26040002300040 1\n",
      "siret26040015500040 1\n",
      "siret26040011400013 1\n",
      "siret26040012200057 1\n",
      "siret26050003800013 1\n",
      "siret78292123300014 4\n",
      "siret26060010100018 1\n",
      "siret26060002800013 1\n",
      "siret26060006900017 1\n",
      "siret26060011900010 1\n",
      "siret26060013500057 1\n",
      "siret78259658900013 2\n",
      "siret26060331100010 1\n",
      "siret26060331100051 1\n",
      "siret26060070500081 1\n",
      "siret26060070500016 1\n",
      "siret26060070500099 4\n",
      "siret78259658900062 1\n",
      "siret26060070500297 1\n",
      "siret26060070500073 2\n",
      "siret26060070500024 1\n",
      "siret26060070500123 1\n",
      "siret26060070500107 1\n",
      "siret26070021600013 1\n",
      "siret26070025700017 1\n",
      "siret20001167400013 1\n",
      "siret26070006700010 1\n",
      "siret26070011700013 1\n",
      "siret26070010900010 1\n",
      "siret26070019000010 1\n",
      "siret26070015800017 1\n",
      "siret26070018200017 1\n",
      "siret26090001400010 1\n",
      "siret26090010500016 1\n",
      "siret26100736300011 1\n",
      "siret26100004600019 1\n",
      "siret26120012500019 1\n",
      "siret20001813300013 1\n",
      "siret26120013300013 1\n",
      "siret26120648600019 1\n",
      "siret20001124500012 1\n",
      "siret26130008100096 16\n",
      "siret26130008100153 4\n",
      "siret26130008100088 2\n",
      "siret26130008100138 2\n",
      "siret26130008100120 1\n",
      "siret15100002300300 1\n",
      "siret26130008100393 1\n",
      "siret26130008100484 2\n",
      "siret26140093100018 2\n",
      "siret78070959800012 2\n",
      "siret26140093100034 1\n",
      "finess140028044 1\n",
      "finess140030891 1\n",
      "finess140032707 1\n",
      "siret26160026600017 1\n",
      "siret26170037100014 1\n",
      "siret26170030600069 1\n",
      "siret26180020500013 1\n",
      "siret26190280300012 1\n",
      "finess190013235 1\n",
      "finess210006938 1\n",
      "finess210012464 1\n",
      "siret22210001800134 1\n",
      "siret26210007600070 1\n",
      "siret26210007600013 4\n",
      "siret26210008400017 1\n",
      "siret26210002700016 1\n",
      "siret77820427100010 2\n",
      "finess230004897 1\n",
      "siret26240562400012 1\n",
      "siret26240570700015 1\n",
      "siret26240571500018 1\n",
      "siret26240587100019 1\n",
      "siret20005293400011 1\n",
      "siret26240588900011 1\n",
      "siret20005293400029 1\n",
      "siret26250176000017 2\n",
      "siret26250411100010 1\n",
      "siret26250047300018 1\n",
      "siret26250434300019 1\n",
      "siret26250176000066 2\n",
      "siret26250176000231 1\n",
      "siret26260007500010 1\n",
      "siret26260001800010 1\n",
      "siret26420030400832 1\n",
      "siret26270285500012 1\n",
      "siret26270286300065 1\n",
      "siret26270289700014 1\n",
      "siret26280090700012 1\n",
      "siret20002305900021 2\n",
      "siret20002305900039 1\n",
      "siret26290010300017 1\n",
      "siret26290012900012 1\n",
      "siret15100002300136 1\n",
      "siret26290011100028 1\n",
      "siret20002305900112 2\n",
      "siret20002305900054 1\n",
      "siret20002305900047 1\n",
      "siret20002305900252 1\n",
      "siret20002305900088 1\n",
      "siret20002305900294 2\n",
      "finess290034917 1\n",
      "finess290034925 1\n",
      "finess290034958 1\n",
      "finess290034966 1\n",
      "finess290034974 1\n",
      "finess290034982 1\n",
      "finess290034990 1\n",
      "finess290035054 1\n",
      "finess290036334 1\n",
      "finess290036722 1\n",
      "finess290036755 1\n",
      "siret26200007800010 1\n",
      "siret26201015000015 1\n",
      "siret20001124500038 1\n",
      "siret26300004400093 1\n",
      "siret26300014300119 1\n",
      "siret26300015000015 1\n",
      "siret26300003600131 2\n",
      "siret50912113300011 1\n",
      "finess300017910 1\n",
      "finess300018231 1\n",
      "finess300018249 1\n",
      "finess300018256 1\n",
      "finess300019395 1\n",
      "finess300019437 1\n",
      "siret26300003600032 2\n",
      "siret26300003600255 1\n",
      "siret26300003600107 1\n",
      "siret26310011700013 1\n",
      "siret26310012500016 2\n",
      "siret26310060400010 1\n",
      "siret81515871200118 1\n",
      "siret26310012500511 1\n",
      "siret26310012500529 1\n",
      "siret26310012500065 3\n",
      "siret26310012500594 1\n",
      "siret26310012500610 1\n",
      "siret26310012500628 1\n",
      "siret26310012500032 1\n",
      "siret77692637000037 2\n",
      "siret26310012500040 2\n",
      "siret26310012500057 2\n",
      "siret26310012500180 2\n",
      "siret20002275400010 1\n",
      "siret26320008100010 1\n",
      "siret20001324100019 1\n",
      "siret26320012300010 1\n",
      "siret26320013100013 1\n",
      "siret26320014900015 1\n",
      "siret26320019800061 1\n",
      "siret78183171400014 2\n",
      "finess330781303 1\n",
      "siret26330582300449 1\n",
      "siret26330582300076 1\n",
      "siret26330582300035 2\n",
      "siret26330582300092 2\n",
      "siret26330582300068 1\n",
      "siret26340007900012 1\n",
      "siret26340008700015 1\n",
      "siret26340016000382 2\n",
      "siret78821496300035 1\n",
      "siret26340014500011 1\n",
      "siret26340015200017 1\n",
      "siret26340012900015 1\n",
      "siret26340016000408 4\n",
      "siret26340016000085 4\n",
      "siret26340008700056 1\n",
      "siret26340016000127 2\n",
      "finess340020304 1\n",
      "finess340020312 1\n",
      "finess340020346 1\n",
      "finess340020353 1\n",
      "finess340021260 1\n",
      "finess340021286 1\n",
      "finess340021294 1\n",
      "finess340021302 1\n",
      "siret26340016000440 2\n",
      "siret26340016000432 1\n",
      "finess340025238 1\n",
      "finess340025246 1\n",
      "finess340025279 1\n",
      "finess340027739 1\n",
      "siret26340010300010 1\n",
      "siret26340016000036 2\n",
      "siret26340016000226 1\n",
      "siret26340016000010 2\n",
      "siret26340016000457 1\n",
      "siret26350001900017 1\n",
      "siret26350011800017 1\n",
      "siret26350009200014 1\n",
      "siret26350003500013 1\n",
      "siret26350002700010 1\n",
      "siret26350007600017 4\n",
      "siret77773916000011 2\n",
      "siret26350007600165 1\n",
      "siret26350007600025 2\n",
      "finess350040499 1\n",
      "finess350051470 1\n",
      "finess350053013 1\n",
      "siret26360013200017 1\n",
      "siret26360002500013 1\n",
      "siret26360005800014 1\n",
      "siret26360010800017 1\n",
      "siret26370018900024 2\n",
      "siret26370018900032 1\n",
      "siret26370018900016 2\n",
      "siret26370014800111 1\n",
      "siret26370018900479 1\n",
      "siret26370018900131 1\n",
      "siret26370018900107 1\n",
      "siret26370018900222 2\n",
      "siret26370018900073 1\n",
      "siret26370018900115 1\n",
      "siret26370018900149 1\n",
      "siret26370018900370 1\n",
      "siret26370018900453 1\n",
      "siret26370018900206 1\n",
      "siret26380030200014 2\n",
      "siret26380022900019 1\n",
      "siret26380003900012 1\n",
      "siret26380029400013 1\n",
      "siret26380014600015 1\n",
      "siret26380030200469 1\n",
      "siret26380030200402 1\n",
      "siret26380030200394 1\n",
      "siret26380030200477 1\n",
      "siret26380030200030 2\n",
      "siret26410013200010 1\n",
      "siret26410010800044 1\n",
      "siret26410015700017 1\n",
      "siret26420039500012 1\n",
      "siret26420008000028 1\n",
      "siret26420028800019 1\n",
      "siret26420009800012 1\n",
      "siret26420023900012 1\n",
      "siret26420003100062 1\n",
      "siret26420030400618 1\n",
      "siret26420030400592 1\n",
      "finess420013187 1\n",
      "siret26420030400840 1\n",
      "siret26420041100017 1\n",
      "siret26420030400022 1\n",
      "siret26420030400063 2\n",
      "siret26420030400030 2\n",
      "siret26440013600018 4\n",
      "siret26440013600711 1\n",
      "siret26440306400084 1\n",
      "siret26440007800012 1\n",
      "siret26440306400092 1\n",
      "siret53225430700020 2\n",
      "siret26440310600018 1\n",
      "siret26440310600026 1\n",
      "siret26440304900044 1\n",
      "siret26440304900077 1\n",
      "siret26440029200019 1\n",
      "siret26440005200017 1\n",
      "siret26440013600026 2\n",
      "siret26440013600422 1\n",
      "siret26440013600075 1\n",
      "siret26440013600133 1\n",
      "siret26440013600463 1\n",
      "siret26440013600638 1\n",
      "siret26440013600596 1\n",
      "siret26440013600653 1\n",
      "siret26440013600612 1\n",
      "siret26440013600588 1\n",
      "siret26440013600620 1\n",
      "siret26440013600604 1\n",
      "siret26440013600646 1\n",
      "siret26440013600661 1\n",
      "siret26440013600679 1\n",
      "finess440050458 1\n",
      "finess440050466 1\n",
      "finess440055747 1\n",
      "siret26450009100014 1\n",
      "siret26450001800017 1\n",
      "siret26450014100017 2\n",
      "siret26450007500017 1\n",
      "siret26450025700011 1\n",
      "siret26450009100030 2\n",
      "siret26450009100212 1\n",
      "siret26450009100337 1\n",
      "siret26460017200011 1\n",
      "siret26470348900049 1\n",
      "siret26470349700018 1\n",
      "siret26470249900023 1\n",
      "siret26330582300506 1\n",
      "siret26480012900027 1\n",
      "siret26480004600015 1\n",
      "siret26480008700019 1\n",
      "siret26480005300011 1\n",
      "siret26490003600015 2\n",
      "siret53225430700012 2\n",
      "siret26490664500017 1\n",
      "siret26490664500058 1\n",
      "siret26490008500012 1\n",
      "siret26490048100013 1\n",
      "siret26490049900015 1\n",
      "siret26490046500016 1\n",
      "siret26490667800042 1\n",
      "siret26490667800075 1\n",
      "finess490020971 1\n",
      "siret26490003600106 1\n",
      "siret26500101600012 1\n",
      "siret26500103200019 1\n",
      "siret26500106500019 1\n",
      "siret26500109900018 1\n",
      "siret78070959800020 1\n",
      "siret26510004000012 1\n",
      "siret78042143400017 2\n",
      "siret26510005700180 2\n",
      "siret26510005700040 1\n",
      "siret26510005700032 2\n",
      "siret26510005700065 1\n",
      "finess510025380 1\n",
      "siret26520002200019 1\n",
      "siret26520006300013 1\n",
      "siret26520010500012 1\n",
      "siret26520015400010 1\n",
      "siret26530333900013 1\n",
      "siret26530014500017 1\n",
      "siret26530015200013 1\n",
      "siret26530333900054 1\n",
      "siret26530036800015 1\n",
      "siret26530333900021 1\n",
      "siret20004216600112 1\n",
      "siret26540648800022 1\n",
      "siret20004216600179 1\n",
      "siret26540006900018 1\n",
      "siret20004216600013 2\n",
      "siret78333606800029 2\n",
      "siret20004216600161 2\n",
      "siret20004216600047 1\n",
      "siret20004216600039 1\n",
      "siret20004216600088 1\n",
      "siret20004216600021 1\n",
      "siret26560034600018 1\n",
      "siret26560017100010 1\n",
      "siret26560043700015 1\n",
      "siret26570280300528 1\n",
      "siret26570280300346 1\n",
      "siret15100002300219 1\n",
      "siret26570015300017 1\n",
      "siret26570280300411 1\n",
      "siret26570280300031 1\n",
      "siret26570280300486 1\n",
      "finess570026575 1\n",
      "siret26570280300510 2\n",
      "siret26580011000016 1\n",
      "siret26590671900017 4\n",
      "siret78369734500016 2\n",
      "siret26590671900397 1\n",
      "siret26590671900389 2\n",
      "finess590048468 1\n",
      "finess590060901 1\n",
      "finess590062279 1\n",
      "siret26590671900058 2\n",
      "siret26590671900116 1\n",
      "siret26590671900181 2\n",
      "siret26590671900165 1\n",
      "siret26590671900124 2\n",
      "siret26590671900157 1\n",
      "siret26590671900173 2\n",
      "siret26590671900322 2\n",
      "siret26590671900330 1\n",
      "siret26590671900348 1\n",
      "siret26600703800018 1\n",
      "siret26600024900018 1\n",
      "siret26750045200714 1\n",
      "siret26610054400011 1\n",
      "siret26610055100016 1\n",
      "siret26610056900018 1\n",
      "siret26620938600017 1\n",
      "siret26750045200755 1\n",
      "siret26630746100019 2\n",
      "siret77921386700020 2\n",
      "siret26630746100050 2\n",
      "siret26630746100308 2\n",
      "siret26630746100084 1\n",
      "siret26630746100076 1\n",
      "siret26640550500014 1\n",
      "siret26750045200581 1\n",
      "siret26660007100010 1\n",
      "siret26670057400012 2\n",
      "siret77885330900046 1\n",
      "finess670017979 1\n",
      "finess670018779 1\n",
      "finess670018787 1\n",
      "siret26670057400459 1\n",
      "siret26670057400079 1\n",
      "siret26670057400095 4\n",
      "siret26670057400186 1\n",
      "siret26670057400202 1\n",
      "siret26690022400012 1\n",
      "siret26690009100064 1\n",
      "siret26690018200087 1\n",
      "siret26690021600018 1\n",
      "siret26690005900012 1\n",
      "siret26690004200018 1\n",
      "siret20007689100031 1\n",
      "siret77992413300019 2\n",
      "siret26690027300969 2\n",
      "siret26690027300985 2\n",
      "siret26690027300720 1\n",
      "siret26690027300019 2\n",
      "siret26690027300993 1\n",
      "siret26690027301033 1\n",
      "siret43218235000020 1\n",
      "siret26690027301058 1\n",
      "finess690042387 1\n",
      "finess690044649 1\n",
      "siret15100002300433 1\n",
      "siret26690027300217 2\n",
      "siret26690027300324 2\n",
      "siret26690027300100 2\n",
      "siret26690027300910 2\n",
      "siret26690027300977 2\n",
      "siret26690027300159 2\n",
      "siret26690027300365 2\n",
      "siret26690027300126 1\n",
      "siret26690027300357 1\n",
      "siret26690027300266 2\n",
      "siret26690027300316 1\n",
      "siret26690027300274 1\n",
      "siret26690027300654 1\n",
      "siret26710006300010 1\n",
      "siret26710014700011 1\n",
      "siret26710025300017 1\n",
      "siret26710030300010 1\n",
      "siret26710046900035 1\n",
      "siret26710014700078 1\n",
      "siret26710023800018 1\n",
      "siret26710045100033 1\n",
      "siret26720020200013 1\n",
      "siret26730014300018 1\n",
      "siret26730009300049 1\n",
      "siret26740008300064 1\n",
      "siret26740017400012 1\n",
      "siret26750045200672 2\n",
      "siret18000702300021 1\n",
      "siret26750045201720 1\n",
      "siret26750045200599 2\n",
      "siret78428191700012 2\n",
      "siret26750045200474 2\n",
      "siret26750045200516 2\n",
      "siret26750045200466 2\n",
      "siret26750045200300 2\n",
      "siret26750045200227 2\n",
      "siret26750045200243 2\n",
      "siret26750045200524 2\n",
      "siret26750045200052 1\n",
      "siret38304765100013 1\n",
      "siret26750045200045 2\n",
      "siret26750045200284 2\n",
      "siret26750045201274 1\n",
      "siret26750045200201 2\n",
      "siret26750045200235 2\n",
      "siret26750045200623 2\n",
      "siret78425716400037 2\n",
      "siret26750045200698 2\n",
      "siret26750045200854 1\n",
      "siret26750045200847 1\n",
      "siret26750045201191 2\n",
      "siret26750045200995 2\n",
      "siret26750045200680 1\n",
      "siret18000702300013 2\n",
      "siret26750045201480 1\n",
      "siret11009001600012 2\n",
      "siret26760162300015 1\n",
      "siret26760163100018 1\n",
      "siret26760166400019 1\n",
      "siret26760168000130 1\n",
      "siret26760168000015 6\n",
      "siret78111289100010 2\n",
      "siret26760169800017 1\n",
      "siret26760174800010 1\n",
      "siret26760168000023 1\n",
      "siret26760168000049 1\n",
      "siret26780234600010 1\n",
      "siret20003030200018 1\n",
      "siret26790040500015 1\n",
      "siret26800014800018 2\n",
      "siret26800014800059 1\n",
      "siret26800014800125 2\n",
      "finess800016735 1\n",
      "siret26800014800356 1\n",
      "siret26820010200013 1\n",
      "siret20002802500019 1\n",
      "siret26750045200342 1\n",
      "siret26690027300399 1\n",
      "siret15100002300276 1\n",
      "siret26830362500019 1\n",
      "siret26840015700049 1\n",
      "siret26840011600011 1\n",
      "siret26840020700042 1\n",
      "siret26850028700019 1\n",
      "siret20005038300013 1\n",
      "siret26850029500012 1\n",
      "siret20005535800028 1\n",
      "siret20005535800010 2\n",
      "siret20005535800044 1\n",
      "siret20005535800051 1\n",
      "siret20005535800069 1\n",
      "siret20005535800036 1\n",
      "siret20005535800077 1\n",
      "siret26870851800017 4\n",
      "siret26870042400057 1\n",
      "siret26870042400099 1\n",
      "siret26872065300073 1\n",
      "siret26870042400065 1\n",
      "siret26870851800058 2\n",
      "siret26870851800355 1\n",
      "siret26870851800314 1\n",
      "finess870017647 1\n",
      "finess870018181 1\n",
      "siret26880022400019 1\n",
      "siret26880023200012 1\n",
      "siret26880747600018 2\n",
      "siret26880021600015 1\n",
      "siret26880019000012 1\n",
      "siret26890030500015 1\n",
      "siret26750045200417 1\n",
      "siret26750045200532 1\n",
      "siret26750045200540 1\n",
      "siret78425716400060 1\n",
      "siret26750045200979 1\n",
      "siret78425716400086 2\n",
      "finess920029758 1\n",
      "siret26750045200375 2\n",
      "siret26750045200391 2\n",
      "siret26750045200094 2\n",
      "siret26750045200383 2\n",
      "siret26750045200573 2\n",
      "siret26750045200409 2\n",
      "siret15100002300631 1\n",
      "siret26750045200458 1\n",
      "siret80803419300017 1\n",
      "siret26750045200367 2\n",
      "siret77574110100056 1\n",
      "siret77574110100031 2\n",
      "siret26750045200730 1\n",
      "siret26750045200433 2\n",
      "siret26750045200557 2\n",
      "siret26750045200425 2\n",
      "siret26750045200441 2\n",
      "siret26750045200110 2\n",
      "siret26750045200292 2\n",
      "siret26750045200664 1\n",
      "siret15100002300649 1\n",
      "siret26750045200953 1\n",
      "siret26750045200649 1\n",
      "siret26971065300016 1\n",
      "siret26971041400013 2\n",
      "siret26971043000076 1\n",
      "finess970112587 1\n",
      "finess970112793 1\n",
      "finess970112835 1\n",
      "finess970112850 1\n",
      "finess970112884 1\n",
      "finess970113007 1\n",
      "siret26972073600033 1\n",
      "finess970211215 1\n",
      "siret20003452800139 1\n",
      "finess970211231 1\n",
      "siret20003452800154 2\n",
      "siret20003452800162 1\n",
      "siret20003452800170 1\n",
      "siret20003452800188 1\n",
      "finess970213278 1\n",
      "finess970213286 1\n",
      "siret20003001300011 2\n",
      "siret20003001300102 2\n",
      "siret20003001300037 1\n",
      "siret20003001300078 1\n",
      "siret20003001300086 1\n",
      "finess970410536 1\n",
      "finess970410544 1\n",
      "finess970410551 1\n",
      "finess970410569 1\n",
      "finess970410577 1\n",
      "finess970410585 1\n",
      "finess970410593 1\n",
      "finess970410601 1\n",
      "finess970410619 1\n",
      "finess970410627 1\n",
      "finess970410635 1\n",
      "finess970410643 1\n",
      "siret20003001300144 1\n"
     ]
    }
   ],
   "source": [
    "for k in my_list:\n",
    "    print(k, len(my_list[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(my_list, open(\"dict_finess.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finess = pickle.load(open(\"dict_finess.pkl\", \"rb\"))\n",
    "len(finess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accents(w: str) -> str:\n",
    "    \"\"\"Normalize accents and stuff in string.\"\"\"\n",
    "    w2 = w.replace(\"’\", \" \")\n",
    "    return \"\".join(\n",
    "      c for c in unicodedata.normalize(\"NFD\", w2)\n",
    "      if unicodedata.category(c) != \"Mn\")\n",
    "\n",
    "\n",
    "def delete_punct(w: str) -> str:\n",
    "    \"\"\"Delete all puctuation in a string.\"\"\"\n",
    "    return w.lower().translate(\n",
    "          str.maketrans(string.punctuation, len(string.punctuation)*\" \"))\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"Normalize string. Delete puctuation and accents.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        text = delete_punct(text)\n",
    "        text = strip_accents(text)\n",
    "        text = text.replace('\\xa0', ' ')\n",
    "        text = \" \".join(text.split())\n",
    "    return text or \"\"\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    return normalize_text(text).lower().replace('-', ' ')\\\n",
    "              .replace('‐', ' ').replace('  ', ' ')\n",
    "\n",
    "def get_common_words(finess, field, split=True, threshold = 10):\n",
    "    common = {}\n",
    "    for elt in finess:\n",
    "\n",
    "        if split:\n",
    "            v = normalize(elt.get(field, '')).split(' ')\n",
    "        else:\n",
    "            v = [normalize(elt.get(field, ''))]\n",
    "        for w in v:\n",
    "            if w not in common:\n",
    "                common[w] = 0\n",
    "            common[w] += 1\n",
    "\n",
    "        \n",
    "    result = []\n",
    "    for w in common:\n",
    "        if common[w] > threshold:\n",
    "            result.append(w)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_to_index = []\n",
    "for k in finess:\n",
    "    new_elt = {\"name\":[], \"city\":[], \"id\": k}\n",
    "\n",
    "    for elt in finess[k]:\n",
    "\n",
    "        if elt.get('dataesr_city'):\n",
    "            new_elt['city'].append( elt.get('dataesr_city') )\n",
    "        if elt.get('Ligne d’acheminement (CodePostal+Lib commune) ligneacheminement'):\n",
    "            new_elt['city'].append( elt.get('Ligne d’acheminement (CodePostal+Lib commune) ligneacheminement') )\n",
    "\n",
    "        if elt.get('Raison sociale rs'):\n",
    "            new_elt['name'].append(elt.get('Raison sociale rs'))\n",
    "        if elt.get('Raison sociale longue rslongue'):\n",
    "            new_elt['name'].append(elt.get('Raison sociale longue rslongue'))\n",
    "        if elt.get('dataesr_name'):\n",
    "            new_elt['name'].append(elt.get('dataesr_name'))\n",
    "            \n",
    "            \n",
    "    docs_to_index.append(new_elt)\n",
    "    \n",
    "len(docs_to_index)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_cities = []\n",
    "for k in finess:\n",
    "    for elt in finess[k]:\n",
    "        if elt.get('dataesr_city'):\n",
    "            known_cities.append(normalize(elt.get('dataesr_city')))\n",
    "        if elt.get('Ligne d’acheminement (CodePostal+Lib commune) ligneacheminement'):\n",
    "            known_cities.append(normalize(elt.get('Ligne d’acheminement (CodePostal+Lib commune) ligneacheminement')))\n",
    "known_cities = list(set(known_cities) - set('france'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## docker-compose -f docker-compose.local.yml up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(['localhost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_cities = [c for c in get_common_words(finess, 'city',split=True, threshold=0) if len(c)>2]\n",
    "#main_cities = list(set(main_cities) - set(['france']))\n",
    "#main_names = list(set(get_common_words(finess, 'name',5)) - set(main_cities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_remove = []#\"hopital\", \"hospitalier\", \"service\", \"centre\", \"universitaire\", \"regional\", \"saint\",\n",
    "                  #\"chu\", \"chr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-1419897142cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'main_names' is not defined"
     ]
    }
   ],
   "source": [
    "main_names[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_filters():\n",
    "    char_filters =  {}\n",
    "    char_filters[\"keep_digits_only\"] = {\n",
    "          \"type\": \"pattern_replace\",\n",
    "          \"pattern\": \"\\D+\",\n",
    "          \"replacement\": \" \"\n",
    "        }\n",
    "    char_filters[\"remove_digits\"] = {\n",
    "          \"type\": \"pattern_replace\",\n",
    "          \"pattern\": \"[0-9]\",\n",
    "          \"replacement\": \" \"\n",
    "        }\n",
    "    char_filters[\"remove_space\"] = {\n",
    "          \"type\": \"pattern_replace\",\n",
    "          \"pattern\": \" |_\",\n",
    "          \"replacement\": \"\"\n",
    "        }\n",
    "    return char_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filters(main_cities, main_names):\n",
    "    filters = {}\n",
    "    filters[\"keep_cities\"]= {\n",
    "      \"type\": \"keep\",\n",
    "      \"keep_words\": main_cities\n",
    "    }\n",
    "    filters[\"city_remover\"]= {\n",
    "        \"type\": \"stop\",\n",
    "        \"ignore_case\": True,\n",
    "        \"stopwords\": main_cities\n",
    "      }\n",
    "    filters[\"common_names_filter\"]= {\n",
    "        \"type\": \"stop\",\n",
    "        \"ignore_case\": True,\n",
    "        \"stopwords\": main_names\n",
    "      }\n",
    "    filters[\"french_stop\"] = {\n",
    "              \"type\":       \"stop\",\n",
    "              \"stopwords\":  \"_french_\" \n",
    "    }\n",
    "    filters[\"english_stop\"] = {\n",
    "          \"type\":       \"stop\",\n",
    "          \"stopwords\":  \"_english_\" \n",
    "        }\n",
    "\n",
    "    filters[\"extract_digits\"]={\n",
    "      \"type\": \"keep_types\",\n",
    "      \"types\": [ \"<NUM>\" ]\n",
    "    }\n",
    "\n",
    "    filters[\"length_min_2_char\"]= {\n",
    "          \"type\": \"length\",\n",
    "          \"min\": 2\n",
    "        }\n",
    "\n",
    "    filters[\"length_min_3_char\"]= {\n",
    "          \"type\": \"length\",\n",
    "          \"min\": 3\n",
    "        }\n",
    "\n",
    "    filters[\"length_min_4_char\"]= {\n",
    "          \"type\": \"length\",\n",
    "          \"min\": 4\n",
    "        }\n",
    "\n",
    "    filters[\"length_min_5_char\"]= {\n",
    "          \"type\": \"length\",\n",
    "          \"min\": 5\n",
    "        }\n",
    "\n",
    "    filters[\"length_2_5_char\"]= {\n",
    "          \"type\": \"length\",\n",
    "          \"min\": 2,\n",
    "          \"max\": 5\n",
    "        }\n",
    "\n",
    "    filters[\"french_elision\"]= {\n",
    "          \"type\": \"elision\",\n",
    "          \"articles_case\": True,\n",
    "          \"articles\": [\"l\", \"m\", \"t\", \"qu\", \"n\", \"s\", \"j\", \"d\", \"c\", \"jusqu\", \"quoiqu\", \"lorsqu\", \"puisqu\"]\n",
    "        }\n",
    "\n",
    "    filters[\"french_stemmer\"]= {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"light_french\"\n",
    "        }\n",
    "\n",
    "    filters[\"english_stemmer\"]= {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"light_english\"\n",
    "        }\n",
    "\n",
    "    filters[\"underscore_remove\"]= {\n",
    "        \"type\": \"pattern_replace\",\n",
    "        \"pattern\": \"(-|_)\",\n",
    "        \"replacement\": \" \"\n",
    "      }\n",
    "\n",
    "    filters[\"remove_space\"] = {\n",
    "      \"type\": \"pattern_replace\",\n",
    "      \"pattern\": \" \",\n",
    "      \"replacement\": \"\"\n",
    "    }\n",
    "    return filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizers():\n",
    "    tokenizers = {}\n",
    "    tokenizers[\"tokenizer_ngram_3_8\"] = {\n",
    "              \"type\": \"ngram\",\n",
    "              \"min_gram\": 3,\n",
    "              \"max_gram\": 8,\n",
    "              \"token_chars\": [\n",
    "                \"letter\",\n",
    "                \"digit\"\n",
    "              ]\n",
    "            }\n",
    "#tokenizers[\"code_tokenizer\"]= {\n",
    "#          \"type\": \"simple_pattern\",\n",
    "#          \"pattern\": \"([A-Za-z\\-\\_]{1,5})(.{0,1})([0-9]{1,5})\"\n",
    "#        }\n",
    "\n",
    "    tokenizers['code_tokenizer']=  {\n",
    "          \"type\": \"pattern\",\n",
    "          \"pattern\": \"_|\\W+\"\n",
    "        }\n",
    "\n",
    "    tokenizers[\"code_tokenizer_lucky\"]= {\n",
    "          \"type\": \"simple_pattern\",\n",
    "          \"pattern\": \"(UMR|U|FR|EA|UPR|UR|CIC|GDR)(.{0,4})([0-9]{2,4})\"\n",
    "        }\n",
    "    return tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analyzers():\n",
    "\n",
    "    analyzers = {}\n",
    "    analyzers['analyzer_digits'] ={\n",
    "        \"tokenizer\": \"standard\",\n",
    "        \"char_filter\": [\"keep_digits_only\"],\n",
    "        \"filter\": [ \"length_2_5_char\" ]\n",
    "        }\n",
    "\n",
    "        \n",
    "    analyzers[\"analyzer_city\"] = {\n",
    "            \"tokenizer\": \"standard\",\n",
    "            \"char_filter\": [\"remove_digits\"],\n",
    "            \"filter\": [\"lowercase\", \n",
    "                       \"icu_folding\",\n",
    "                       \"keep_cities\"\n",
    "                      ]\n",
    "          }\n",
    "\n",
    "\n",
    "    analyzers[\"analyzer_name\"] =  {\n",
    "            \"tokenizer\": \"icu_tokenizer\",\n",
    "            \"filter\": [\n",
    "                \"french_elision\",\n",
    "                \"icu_folding\",\n",
    "                \"french_stop\",\n",
    "                \"english_stop\",\n",
    "                \"lowercase\",\n",
    "                \"city_remover\",\n",
    "                \"common_names_filter\"\n",
    "            ]\n",
    "          }\n",
    "\n",
    "    return analyzers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_index_finess():\n",
    "    myIndex = 'index-finess'\n",
    "    print(\"deleting \"+myIndex, end=':', flush=True)\n",
    "    del_docs = es.delete_by_query(index=myIndex, body={\"query\": {\"match_all\": {}}})\n",
    "    print(del_docs, flush=True)\n",
    "    del_index = es.indices.delete(index=myIndex, ignore=[400, 404])\n",
    "    print(del_index, flush=True)\n",
    "    return \n",
    "\n",
    "def reset_index_finess(filters, char_filters, tokenizers, analyzers):\n",
    "\n",
    "    myIndex = 'index-finess'\n",
    "    try:\n",
    "        delete_index_finess()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    setting_finess = {\n",
    "        \"index\":{\n",
    "            \"max_ngram_diff\":8\n",
    "        },\n",
    "        \"analysis\": {        \n",
    "            \"char_filter\": char_filters,\n",
    "            \"filter\": filters,\n",
    "            \"analyzer\": analyzers,\n",
    "            \"tokenizer\": tokenizers\n",
    "        }\n",
    "      }\n",
    "    \n",
    "                \n",
    "    mapping_finess={\n",
    "      \"properties\": {\n",
    "        \"name\":    { \n",
    "            \"type\": \"text\",\n",
    "             \"boost\": 5,\n",
    "            \"analyzer\": \"analyzer_name\"\n",
    "        },\n",
    "        \"city\":    { \n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\":\"analyzer_name\",\n",
    "            \n",
    "            \"fields\":{  \n",
    "                  \"digits\":{  \n",
    "                     \"type\":\"text\",\n",
    "                     \"analyzer\":\"analyzer_digits\"\n",
    "                  }\n",
    "                ,\"city\":{  \n",
    "                     \"type\":\"text\",\n",
    "                     \"analyzer\":\"analyzer_city\"\n",
    "                  }\n",
    "            }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    response = es.indices.create(\n",
    "        index=myIndex,\n",
    "        body={\n",
    "            \"settings\": setting_finess,\n",
    "            \"mappings\": mapping_finess\n",
    "            \n",
    "        },\n",
    "        ignore=400 # ignore 400 already exists code\n",
    "    )\n",
    "\n",
    "    if 'acknowledged' in response:\n",
    "        if response['acknowledged'] == True:\n",
    "            print (\"INDEX MAPPING SUCCESS FOR INDEX:\", response['index'], flush=True)\n",
    "            \n",
    "    print(response, flush=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting index-finess:{'took': 108, 'timed_out': False, 'total': 593, 'deleted': 593, 'batches': 1, 'version_conflicts': 0, 'noops': 0, 'retries': {'bulk': 0, 'search': 0}, 'throttled_millis': 0, 'requests_per_second': -1.0, 'throttled_until_millis': 0, 'failures': []}\n",
      "{'acknowledged': True}\n",
      "INDEX MAPPING SUCCESS FOR INDEX: index-finess\n",
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'index-finess'}\n"
     ]
    }
   ],
   "source": [
    "filters = get_filters(known_cities, names_to_remove)\n",
    "char_filters = get_char_filters()\n",
    "tokenizers = get_tokenizers()\n",
    "analyzers = get_analyzers()\n",
    "res = {}\n",
    "\n",
    "reset_index_finess(filters, char_filters, tokenizers, analyzers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(593, [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/elasticsearch/connection/base.py:177: ElasticsearchDeprecationWarning: [types removal] Specifying types in bulk requests is deprecated.\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "actions = [\n",
    "{\n",
    "    \"_index\": \"index-finess\",\n",
    "    \"_type\": \"_doc\",\n",
    "    \"_id\": j,\n",
    "    \"_source\": docs_to_index[j] \n",
    "}\n",
    "        for j in range(0, len(docs_to_index))\n",
    "]\n",
    "len(actions)\n",
    "\n",
    "print(helpers.bulk(es, actions), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_for_count(x, matching_field):\n",
    "    \n",
    "    return x.lower()[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(input_str, search_fields, size=20, verbose=False, highlights=[], fuzzy_ok=False):\n",
    "\n",
    "    myIndex = \"index-finess\"\n",
    "    s = Search(using=es, index=myIndex)\n",
    "    for f in highlights:\n",
    "        s = s.highlight(f)\n",
    "\n",
    "\n",
    "    s = s.query(\"multi_match\", query=input_str,\n",
    "            minimum_should_match=1,\n",
    "            fuzziness=\"auto\",\n",
    "            fields=search_fields)\n",
    "\n",
    "    s = s[0:size]\n",
    "    res = s.execute()\n",
    "    hits = res.hits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    id_res=\"\"\n",
    "    if len(hits)>0:\n",
    "        max_score = hits[0].meta.score\n",
    "\n",
    "\n",
    "    res_ids = []\n",
    "    scores = []\n",
    "    highlights={}\n",
    "    nb_matches = {}\n",
    "    matches_frag = {}\n",
    "\n",
    "    for hit in hits:\n",
    "\n",
    "        res_ids.append(hit.id)\n",
    "        scores.append(hit.meta.score)\n",
    "        highlights[hit.id]=[]\n",
    "\n",
    "\n",
    "        for matching_field in hit.meta.highlight:\n",
    "            for fragment in hit.meta.highlight[matching_field]:\n",
    "                highlights[hit.id].append(fragment)\n",
    "\n",
    "                matches = [normalize_for_count(e.get_text(), matching_field) for e in BeautifulSoup(fragment, 'lxml').find_all('em')]\n",
    "\n",
    "\n",
    "                if hit.id not in nb_matches:\n",
    "                    nb_matches[hit.id] = 0\n",
    "                    matches_frag[hit.id] = []\n",
    "                matches_frag[hit.id] += matches\n",
    "                matches_frag[hit.id] = list(set(matches_frag[hit.id]))\n",
    "                nb_matches[hit.id] = len(matches_frag[hit.id])\n",
    "\n",
    "\n",
    "\n",
    "    #print(scores)\n",
    "    return {'ids': res_ids, 'highlights': highlights, 'nb_matches': nb_matches}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_name(x, verbose=False):\n",
    "    return get_info(x, ['name'], size=200, verbose=verbose, highlights=['name'])\n",
    "def get_match_city(x, verbose=False):\n",
    "    return get_info(x, ['city.city'], size=200, verbose=verbose, highlights=['city.city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['siret26130008100096',\n",
       "  'siret26130008100153',\n",
       "  'siret78292123300014',\n",
       "  'siret26130008100088',\n",
       "  'siret26130008100138',\n",
       "  'siret26130008100484',\n",
       "  'siret26130008100120',\n",
       "  'siret15100002300300',\n",
       "  'siret26130008100393'],\n",
       " 'highlights': {'siret26130008100096': ['<em>Marseille</em>',\n",
       "   '<em>Marseille</em>',\n",
       "   '<em>Marseille</em>',\n",
       "   '<em>Marseille</em>',\n",
       "   '<em>Marseille</em>'],\n",
       "  'siret26130008100153': ['<em>Marseille</em>',\n",
       "   '13015 <em>MARSEILLE</em>',\n",
       "   '<em>Marseille</em>',\n",
       "   '13015 <em>MARSEILLE</em>'],\n",
       "  'siret78292123300014': ['<em>Marseille</em>',\n",
       "   '<em>Marseille</em>',\n",
       "   '13273 <em>MARSEILLE</em> CEDEX 09'],\n",
       "  'siret26130008100088': ['<em>Marseille</em>', '13005 <em>MARSEILLE</em>'],\n",
       "  'siret26130008100138': ['<em>Marseille</em>',\n",
       "   '13274 <em>MARSEILLE</em> CEDEX 09'],\n",
       "  'siret26130008100484': ['<em>Marseille</em>',\n",
       "   '13385 <em>MARSEILLE</em> CEDEX 05'],\n",
       "  'siret26130008100120': ['13274 <em>MARSEILLE</em> CEDEX 09'],\n",
       "  'siret15100002300300': ['13384 <em>MARSEILLE</em> CEDEX 13'],\n",
       "  'siret26130008100393': ['13005 <em>MARSEILLE</em>']},\n",
       " 'nb_matches': {'siret26130008100096': 1,\n",
       "  'siret26130008100153': 1,\n",
       "  'siret78292123300014': 1,\n",
       "  'siret26130008100088': 1,\n",
       "  'siret26130008100138': 1,\n",
       "  'siret26130008100484': 1,\n",
       "  'siret26130008100120': 1,\n",
       "  'siret15100002300300': 1,\n",
       "  'siret26130008100393': 1}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_match_city(\"paoli calmette marseille\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_unstructured(query='', raison_sociale=None, city=None):\n",
    "\n",
    "    logs = \"\"\n",
    "    logs += \"<h1> &#128269; {}</h1>\".format(query)\n",
    "    x = query\n",
    "    if raison_sociale is None:\n",
    "        raison_sociale = x\n",
    "    if city is None:\n",
    "        city = x\n",
    "   \n",
    "    matching_info={}\n",
    "    matching_info['city'] = get_match_city(x)\n",
    "    matching_info['name'] = get_match_name(x)\n",
    "\n",
    "    strategies=[]\n",
    "\n",
    "    strategies.append(\"name;city\")\n",
    "\n",
    "    return match_structured(matching_info, strategies, logs)\n",
    "\n",
    "def match_structured(matching_info, strategies, logs):\n",
    "    \n",
    "    \n",
    "    all_matches = {}\n",
    "    field_matches = {}\n",
    "    min_match_for_field = {}\n",
    "    for f in matching_info:\n",
    "        for match_id in matching_info[f].get('nb_matches', {}):\n",
    "            if match_id not in all_matches:\n",
    "                all_matches[match_id] = 0\n",
    "                field_matches[match_id] = []\n",
    "            all_matches[match_id] += matching_info[f].get('nb_matches', {})[match_id]\n",
    "            if f not in field_matches[match_id]:\n",
    "                field_matches[match_id].append(f)\n",
    "                \n",
    "        min_match_for_field[f] = 1\n",
    "    \n",
    "    relevant_matches = {}\n",
    "    \n",
    "    \n",
    "    final_results = {}\n",
    "    forbidden_id = []\n",
    "    \n",
    "    logs += \"<ol> \"\n",
    "    for strat in strategies:\n",
    "        stop_current_start = False\n",
    "        current_strat_answers = []\n",
    "        strat_fields = strat.split(';')\n",
    "        logs += \"<li>Strategie testée : {}\".format(strat)\n",
    "        \n",
    "        indiv_ids = [matching_info[field]['ids'] for field in strat_fields]\n",
    "        strat_ids = set(indiv_ids[0]).intersection(*indiv_ids)\n",
    "\n",
    "        if len(strat_ids) == 0:\n",
    "            logs += \" &empty; </li>\"\n",
    "            continue\n",
    "        logs += \"</li></br>\"\n",
    "            \n",
    "            \n",
    "        max_number = {}\n",
    "        logs += \"<ol> \"\n",
    "        for potential_id in strat_ids:\n",
    "            logs += \" <li> Id potentiel : {}<br/></li>\".format(potential_id)\n",
    "            current_match = {'id': potential_id}\n",
    "            for field in strat_fields:\n",
    "                current_match[field+'_match'] = 0\n",
    "                #probleme avec les highlights\n",
    "                bbb =  matching_info[field]['nb_matches'][potential_id]\n",
    "                if potential_id in matching_info[field]['nb_matches']:\n",
    "                    current_match[field+'_match'] = matching_info[field]['nb_matches'][potential_id]\n",
    "                    \n",
    "                    current_highlights = matching_info[field]['highlights'][potential_id]\n",
    "                    current_highlights = [e.replace('<em>', '<strong>').replace('</em>', '</strong>') for e in current_highlights]\n",
    "                    logs += \"     - {} {} : {}<br/>\".format(\n",
    "                            matching_info[field]['nb_matches'][potential_id],\n",
    "                            field,\n",
    "                            current_highlights)    \n",
    "          \n",
    "                \n",
    "                if field not in max_number:\n",
    "                    max_number[field] = 0\n",
    "                    #if field == 'name':\n",
    "                    #    max_number[field] = 2\n",
    "\n",
    "                max_number[field] = max(max_number[field], current_match[field+'_match'])\n",
    "\n",
    "            current_strat_answers.append(current_match)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if len(max_number)>0:\n",
    "            logs += \"<li> &#9989; Nombre de match par champ : {}<br/></li>\".format(max_number)\n",
    "            \n",
    "        logs += \"</ol>\" # end of potential ids\n",
    "                \n",
    "        if len(strat_ids) == 0:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        \n",
    "        current_potential_ids = strat_ids\n",
    "        retained_id_for_strat = []\n",
    "        ignored_id = []\n",
    "        logs += \"Parcours des champs de la stratégie :\"\n",
    "        for field in strat_fields:\n",
    "            logs += \"{}...\".format(field)\n",
    "            if field in [\"city\", \"code_fuzzy\"]:\n",
    "                logs += \"(ignoré)...\"\n",
    "                continue\n",
    " \n",
    "            for potential_id in current_potential_ids:\n",
    "                if potential_id in matching_info[field]['nb_matches']:\n",
    "                    if  matching_info[field]['nb_matches'][potential_id] == max_number[field]:\n",
    "                        if max_number[field] >= min_match_for_field[field]:\n",
    "                            retained_id_for_strat.append(potential_id)\n",
    "                        else:\n",
    "                            logs +=\"<br/> &#128584; \"+potential_id+\" ignoré car {} {} est insuffisant ({} attendus au min)\".format(\n",
    "                                max_number[field], field, min_match_for_field[field])\n",
    "                            ignored_id.append(potential_id)\n",
    "                    elif potential_id not in matching_info.get('code', {}).get('ids', []):\n",
    "                        logs += \"<br/> &#10060; {} ajouté à la black-list car seulement {} {} vs le max est {}\".format(\n",
    "                            potential_id,\n",
    "                            matching_info[field]['nb_matches'][potential_id],\n",
    "                            field,\n",
    "                            max_number[field])\n",
    "                        forbidden_id.append(potential_id)\n",
    "            if len(retained_id_for_strat) == 1:\n",
    "                if ('code' in strat_fields) or ('code_digit' in strat_fields) or ('acronym' in strat_fields) or ('code_fuzzy' in strat_fields):\n",
    "                    logs +=\"<br/> &#9209;&#65039; Arrêt au champ \"+field\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "                    #if verbose:\n",
    "                        #print(\"not stopping because strategy has no code or acronym\")\n",
    "                        #print(matching_info.get('name',{}).get('highlights', {}).get(potential_id))\n",
    "            else:\n",
    "                current_potential_ids = retained_id_for_strat\n",
    "                retained_id_for_strat = []\n",
    "        for x in ignored_id:\n",
    "            retained_id_for_strat.remove(x)\n",
    "        final_results[strat] = list(set(retained_id_for_strat))\n",
    "            \n",
    "    #for res in final_results:\n",
    "        if len(final_results[strat]) == 1:\n",
    "            logs += \"<br/> 1&#65039;&#8419; unique match pour cette stratégie : {} \".format(final_results[strat][0])\n",
    "            if final_results[strat][0] in forbidden_id:\n",
    "                logs += \"&#10060; car dans la black-list\"\n",
    "                continue\n",
    "            \n",
    "                \n",
    "            else:\n",
    "                logs += \" &#128076;<br/>\"\n",
    "                logs += \"<h3>{}</h3>\".format(final_results[strat][0])\n",
    "                return {'match': final_results[strat][0], 'logs': logs}\n",
    "    \n",
    "    return {'match': None, 'logs': logs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'match': 'siret78292123300014',\n",
       " 'logs': \"<h1> &#128269; paoli calmettes marseille</h1><ol> <li>Strategie testée : name;city</li></br><ol>  <li> Id potentiel : siret78292123300014<br/></li>     - 2 name : ['Institut <strong>Paoli</strong>-<strong>Calmettes</strong>', 'INSTITUT <strong>PAOLI</strong> <strong>CALMETTES</strong> RADIOTH GAP', 'Institut <strong>Paoli</strong>-<strong>Calmettes</strong>', 'INSTITUT <strong>PAOLI</strong> <strong>CALMETTES</strong>', 'INSTITUT <strong>PAOLI</strong> <strong>CALMETTES</strong>']<br/>     - 1 city : ['<strong>Marseille</strong>', '<strong>Marseille</strong>', '13273 <strong>MARSEILLE</strong> CEDEX 09']<br/><li> &#9989; Nombre de match par champ : {'name': 2, 'city': 1}<br/></li></ol>Parcours des champs de la stratégie :name...city...(ignoré)...<br/> 1&#65039;&#8419; unique match pour cette stratégie : siret78292123300014  &#128076;<br/><h3>siret78292123300014</h3>\"}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_unstructured(\"paoli calmettes marseille\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'match': 'siret26310012500057',\n",
       " 'logs': \"<h1> &#128269; CHU Rangueil, Toulouse, France.</h1><ol> <li>Strategie testée : name;city</li></br><ol>  <li> Id potentiel : siret26310012500594<br/></li>     - 1 name : ['HOPITAL GARONNE <strong>CHU</strong> TOULOUSE', 'HOPITAL GARONNE <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500180<br/></li>     - 1 name : ['CTRE CASSELARDIT VILLA ANCELY <strong>CHU</strong> TLSE', 'CENTRE DE CASSELARDIT VILLA ANCELY <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['<strong>Toulouse</strong>', '31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500529<br/></li>     - 1 name : ['HOPITAL LARREY <strong>CHU</strong> TLSE', 'HOPITAL LARREY <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500610<br/></li>     - 1 name : ['HJ PSY GEN BOURGEOIS PURPAN <strong>CHU</strong> TLSE', 'HJ PSY GENERALE BOURGEOIS PURPAN <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500628<br/></li>     - 1 name : ['ONCOPOLE <strong>CHU</strong> TOULOUSE', 'ONCOPOLE <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500065<br/></li>     - 1 name : ['HJ PIJ ENFANTS PURPAN <strong>CHU</strong> TLSE', 'HJ PIJ ENFANTS PURPAN <strong>CHU</strong> TOULOUSE', 'HJ PIJ ADOS APJA PURPAN <strong>CHU</strong> TLSE', 'HOPITAL LA GRAVE <strong>CHU</strong> TLSE', 'HOPITAL LA GRAVE <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['31052 <strong>TOULOUSE</strong> CEDEX 3', '31000 <strong>TOULOUSE</strong>', '31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret81515871200118<br/></li>     - 1 name : ['HJ PIJ JARRIGE PETITS GRAVE <strong>CHU</strong> TLSE', 'HJ PIJ JARRIGE PETITS LA GRAVE <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500511<br/></li>     - 1 name : ['HOPITAUX MERE & ENFANTS SITE VIGUIER <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500040<br/></li>     - 1 name : ['HOPITAL PURPAN <strong>CHU</strong> TLSE', 'HOPITAL PURPAN <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['<strong>Toulouse</strong>', '31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500016<br/></li>     - 1 name : ['HOTEL DIEU ST JACQUES <strong>CHU</strong> TOULOUSE', 'HOTEL DIEU SAINT JACQUES <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['<strong>Toulouse</strong>', '31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500057<br/></li>     - 2 name : ['HOPITAL DE <strong>RANGUEIL</strong> <strong>CHU</strong> TOULOUSE', 'HOPITAL DE <strong>RANGUEIL</strong> <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['<strong>Toulouse</strong>', '31059 <strong>TOULOUSE</strong> CEDEX 9']<br/><li> &#9989; Nombre de match par champ : {'name': 2, 'city': 1}<br/></li></ol>Parcours des champs de la stratégie :name...<br/> &#10060; siret26310012500594 ajouté à la black-list car seulement 1 name vs le max est 2<br/> &#10060; siret26310012500180 ajouté à la black-list car seulement 1 name vs le max est 2<br/> &#10060; siret26310012500529 ajouté à la black-list car seulement 1 name vs le max est 2<br/> &#10060; siret26310012500610 ajouté à la black-list car seulement 1 name vs le max est 2<br/> &#10060; siret26310012500628 ajouté à la black-list car seulement 1 name vs le max est 2<br/> &#10060; siret26310012500065 ajouté à la black-list car seulement 1 name vs le max est 2<br/> &#10060; siret81515871200118 ajouté à la black-list car seulement 1 name vs le max est 2<br/> &#10060; siret26310012500511 ajouté à la black-list car seulement 1 name vs le max est 2<br/> &#10060; siret26310012500040 ajouté à la black-list car seulement 1 name vs le max est 2<br/> &#10060; siret26310012500016 ajouté à la black-list car seulement 1 name vs le max est 2city...(ignoré)...<br/> 1&#65039;&#8419; unique match pour cette stratégie : siret26310012500057  &#128076;<br/><h3>siret26310012500057</h3>\"}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_unstructured(\"CHU Rangueil, Toulouse, France.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_match_city(\"CHU Rangueil, Toulouse, France.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['siret26310012500057'],\n",
       " 'highlights': {'siret26310012500057': ['HOPITAL DE <em>RANGUEIL</em> CHU TOULOUSE',\n",
       "   'HOPITAL DE <em>RANGUEIL</em> CHU TOULOUSE']},\n",
       " 'nb_matches': {'siret26310012500057': 1}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_match_name(\"Rangueil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'match': 'siret26310012500040',\n",
       " 'logs': \"<h1> &#128269; Service de Psychiatrie et de Psychologie Médicale, Centre Expert Dépression Résistante FondaMental, CHU Toulouse, Hospital Purpan, ToNIC, Toulouse NeuroImaging Center, Université de Toulouse, Inserm, UPS, Toulouse, France. Electronic address: antoineyrondi@gmail.com.</h1><ol> <li>Strategie testée : name;city</li></br><ol>  <li> Id potentiel : siret26310012500594<br/></li>     - 2 name : ['<strong>HOPITAL</strong> GARONNE <strong>CHU</strong> TOULOUSE', '<strong>HOPITAL</strong> GARONNE <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500180<br/></li>     - 3 name : ['<strong>CENTRE</strong> DE CASSELARDIT VILLA ANCELY', '<strong>CTRE</strong> CASSELARDIT VILLA ANCELY <strong>CHU</strong> TLSE', '<strong>CENTRE</strong> DE CASSELARDIT VILLA ANCELY <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['<strong>Toulouse</strong>', '31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500529<br/></li>     - 2 name : ['<strong>HOPITAL</strong> LARREY <strong>CHU</strong> TLSE', '<strong>HOPITAL</strong> LARREY <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500610<br/></li>     - 2 name : ['HJ PSY GEN BOURGEOIS <strong>PURPAN</strong> <strong>CHU</strong> TLSE', 'HJ PSY GENERALE BOURGEOIS <strong>PURPAN</strong> <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500065<br/></li>     - 3 name : ['HJ PIJ ENFANTS <strong>PURPAN</strong> <strong>CHU</strong> TLSE', 'HJ PIJ ENFANTS <strong>PURPAN</strong> <strong>CHU</strong> TOULOUSE', 'HJ PIJ ADOS APJA <strong>PURPAN</strong> <strong>CHU</strong> TLSE', '<strong>HOPITAL</strong> LA GRAVE <strong>CHU</strong> TLSE', '<strong>HOPITAL</strong> LA GRAVE <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['31052 <strong>TOULOUSE</strong> CEDEX 3', '31000 <strong>TOULOUSE</strong>', '31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500040<br/></li>     - 4 name : ['<strong>Hôpital</strong> <strong>Purpan</strong>', '<strong>HOPITAL</strong> <strong>PURPAN</strong> <strong>CHU</strong> TLSE', '<strong>HOPITAL</strong> <strong>PURPAN</strong> <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['<strong>Toulouse</strong>', '31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500016<br/></li>     - 2 name : ['<strong>Centre</strong> Hospitalier Universitaire de Toulouse', 'HOTEL DIEU ST JACQUES <strong>CHU</strong> TOULOUSE', 'HOTEL DIEU SAINT JACQUES <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['<strong>Toulouse</strong>', '31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500057<br/></li>     - 3 name : ['<strong>Centre</strong> Hospitalier Universitaire de Toulouse', '<strong>HOPITAL</strong> DE RANGUEIL <strong>CHU</strong> TOULOUSE', '<strong>HOPITAL</strong> DE RANGUEIL <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['<strong>Toulouse</strong>', '31059 <strong>TOULOUSE</strong> CEDEX 9']<br/><li> &#9989; Nombre de match par champ : {'name': 4, 'city': 1}<br/></li></ol>Parcours des champs de la stratégie :name...<br/> &#10060; siret26310012500594 ajouté à la black-list car seulement 2 name vs le max est 4<br/> &#10060; siret26310012500180 ajouté à la black-list car seulement 3 name vs le max est 4<br/> &#10060; siret26310012500529 ajouté à la black-list car seulement 2 name vs le max est 4<br/> &#10060; siret26310012500610 ajouté à la black-list car seulement 2 name vs le max est 4<br/> &#10060; siret26310012500065 ajouté à la black-list car seulement 3 name vs le max est 4<br/> &#10060; siret26310012500016 ajouté à la black-list car seulement 2 name vs le max est 4<br/> &#10060; siret26310012500057 ajouté à la black-list car seulement 3 name vs le max est 4city...(ignoré)...<br/> 1&#65039;&#8419; unique match pour cette stratégie : siret26310012500040  &#128076;<br/><h3>siret26310012500040</h3>\"}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=\"Service de Réanimation Néonatale, Centre Hospitalier Universitaire Sud-Réunion, Saint-Pierre, France.\"\n",
    "x=\"Service de Psychiatrie et de Psychologie Médicale, Centre Expert Dépression Résistante FondaMental, CHU Toulouse, Hospital Purpan, ToNIC, Toulouse NeuroImaging Center, Université de Toulouse, Inserm, UPS, Toulouse, France. Electronic address: antoineyrondi@gmail.com.\"\n",
    "match_unstructured(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_unstructured(\"Centre Hospitalier Universitaire (CHU) de Bordeaux, 33000 Bordeaux, France.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(\"http://localhost:9200/index-finess/_analyze\", json={\n",
    "              \"analyzer\" : \"analyzer_name\",\n",
    "              \"text\" : \"Rangueil\"\n",
    "            }).json()\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in finess:\n",
    "    if e.get('Numéro de SIRET siret') == \"26310012500057\":\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Numéro de SIRET siret'] == 26310012500057]['Numéro FINESS ET nofinesset'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
