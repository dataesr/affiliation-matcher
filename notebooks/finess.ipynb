{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime\n",
    "import math\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Q, Search\n",
    "from elasticsearch import helpers\n",
    "import string\n",
    "import json\n",
    "import unicodedata\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prépa du référentiel à partir de finess et dataESR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['Libellé catégorie d’agrégat d’établissement libcategagretab']==\"Centres Hospitaliers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerem/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (1,2,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('etalab-cs1100502-stock-20200914-0418.csv', \n",
    "            sep=';', encoding=\"iso-8859-1\", skiprows=1, header=None)\n",
    "df.columns = [\"Section : structureet\",\n",
    "\"Numéro FINESS ET nofinesset\",\n",
    "\"Numéro FINESS EJ nofinessej\",\n",
    "\"Raison sociale rs\",\n",
    "\"Raison sociale longue rslongue\",\n",
    "\"Complément de raison sociale complrs\",\n",
    "\"Complément de distribution compldistrib\",\n",
    "\"Numéro de voie numvoie\",\n",
    "\"Type de voie typvoie\",\n",
    "\"Libellé de voie voie\",\n",
    "\"Complément de voie compvoie\",\n",
    "\"Lieu-dit / BP lieuditbp\",\n",
    "\"Code Commune commune\",\n",
    "\"Département departement\",\n",
    "\"Libellé département libdepartement\",\n",
    "\"Ligne d’acheminement (CodePostal+Lib commune) ligneacheminement\",\n",
    "\"Téléphone telephone\",\n",
    "\"Télécopie telecopie\",\n",
    "\"Catégorie d’établissement categetab\",\n",
    "\"Libelle catégorie d’établissement libcategetab\",\n",
    "\"Catégorie d’agrégat d’établissement categagretab\",\n",
    "\"Libellé catégorie d’agrégat d’établissement libcategagretab\",\n",
    "\"Numéro de SIRET siret\",\n",
    "\"Code APE codeape\",\n",
    "\"Code MFT codemft\",\n",
    "\"Libelle MFT libmft\",\n",
    "\"Code SPH codesph\",\n",
    "\"Libelle SPH libsph\",\n",
    "\"Date d’ouverture dateouv\",\n",
    "\"Date d’autorisation dateautor\",\n",
    "\"Date de mise à jour sur la structure datemaj\",\n",
    "\"Numéro éducation nationale numuai\"\n",
    "]\n",
    "\n",
    "\n",
    "df2 = df[df['Libellé catégorie d’agrégat d’établissement libcategagretab'].isin(\n",
    "   [\n",
    "       \"Etab.de soins relevant du service de santé des armées\" ,\n",
    "       \"Centres de Lutte contre le Cancer\",\n",
    "       \"Hôpitaux Locaux\",\n",
    "       \"Centres Hospitaliers Régionaux\",\n",
    "       \"Etablissement de Soins Pluridisciplinaire\"\n",
    "     #  \"Centres Hospitaliers\"\n",
    "   ])\n",
    "  ]\n",
    "\n",
    "df2 = df2[[ 'Numéro FINESS ET nofinesset',\n",
    "           \"Raison sociale rs\",\n",
    "       'Raison sociale longue rslongue',\n",
    "     'Ligne d’acheminement (CodePostal+Lib commune) ligneacheminement',\n",
    "           \"Numéro de voie numvoie\",\n",
    "\"Type de voie typvoie\",\n",
    "\"Libellé de voie voie\",\n",
    "\"Complément de voie compvoie\",\n",
    "\"Lieu-dit / BP lieuditbp\",\n",
    "\"Code Commune commune\",\n",
    "    'Numéro de SIRET siret']].reset_index()\n",
    "del df2['index']\n",
    "#df2.to_csv('/home/jerem/work/matcher/project/server/main/finess.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numéro FINESS ET nofinesset</th>\n",
       "      <th>Raison sociale rs</th>\n",
       "      <th>Raison sociale longue rslongue</th>\n",
       "      <th>Ligne d’acheminement (CodePostal+Lib commune) ligneacheminement</th>\n",
       "      <th>Numéro de voie numvoie</th>\n",
       "      <th>Type de voie typvoie</th>\n",
       "      <th>Libellé de voie voie</th>\n",
       "      <th>Complément de voie compvoie</th>\n",
       "      <th>Lieu-dit / BP lieuditbp</th>\n",
       "      <th>Code Commune commune</th>\n",
       "      <th>Numéro de SIRET siret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>300016680</td>\n",
       "      <td>HJ PSY INF JUV CMPEA OUEST MONTAURY</td>\n",
       "      <td>HJ PSY INFANTO JUVENILE ET CMPEA OUEST MONTAUR...</td>\n",
       "      <td>30900 NIMES</td>\n",
       "      <td>3.0</td>\n",
       "      <td>R</td>\n",
       "      <td>DE MONTAURY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189</td>\n",
       "      <td>2.630000e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>300016698</td>\n",
       "      <td>HJ PSY INF JUV CMPEA VAUVERT</td>\n",
       "      <td>HJ PSY INFANTO JUVENILE CMPEA VAUVERT</td>\n",
       "      <td>30600 VAUVERT</td>\n",
       "      <td>28.0</td>\n",
       "      <td>R</td>\n",
       "      <td>SALVADOR ALLENDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341</td>\n",
       "      <td>5.091211e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>300017910</td>\n",
       "      <td>HJ PSY ADULTES BOURDALOUE</td>\n",
       "      <td>HJ PSY ADULTES BOURDALOUE CHU NIMES</td>\n",
       "      <td>30000 NIMES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>R</td>\n",
       "      <td>BOURDALOUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>300782166</td>\n",
       "      <td>HJ PSY INF JUV CMPEA EST PELLECUER</td>\n",
       "      <td>HJ PSY INFANTO JUVENILE CMPEA EST PELLECUER CH...</td>\n",
       "      <td>30006 NIMES CEDEX 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>CITE PAUL GIRAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189</td>\n",
       "      <td>2.630000e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>310014899</td>\n",
       "      <td>HJ PIJ JARRIGE PETITS GRAVE CHU TLSE</td>\n",
       "      <td>HJ PIJ JARRIGE PETITS LA GRAVE CHU TOULOUSE</td>\n",
       "      <td>31059 TOULOUSE CEDEX 9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PL</td>\n",
       "      <td>LANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TSA 60033</td>\n",
       "      <td>555</td>\n",
       "      <td>8.151587e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>310019617</td>\n",
       "      <td>HJ PIJ ENFANTS PURPAN CHU TLSE</td>\n",
       "      <td>HJ PIJ ENFANTS PURPAN CHU TOULOUSE</td>\n",
       "      <td>31052 TOULOUSE CEDEX 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PL</td>\n",
       "      <td>LANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>555</td>\n",
       "      <td>2.631001e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>310019625</td>\n",
       "      <td>HJ PIJ ADOS APJA PURPAN CHU TLSE</td>\n",
       "      <td>HJ PIJ ADOLESCENTS APJA PURPAN CHU TOULOUSE</td>\n",
       "      <td>31000 TOULOUSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PL</td>\n",
       "      <td>DU DR BAYLAC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>555</td>\n",
       "      <td>2.631001e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>310025077</td>\n",
       "      <td>HJ PSY GEN BOURGEOIS PURPAN CHU TLSE</td>\n",
       "      <td>HJ PSY GENERALE BOURGEOIS PURPAN CHU TOULOUSE</td>\n",
       "      <td>31059 TOULOUSE CEDEX 9</td>\n",
       "      <td>330.0</td>\n",
       "      <td>AV</td>\n",
       "      <td>DE GRANDE BRETAGNE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TSA 70034</td>\n",
       "      <td>555</td>\n",
       "      <td>2.631001e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>340020304</td>\n",
       "      <td>HJ PSY ADULTES UNITE GIGNAC</td>\n",
       "      <td>CMP HOSPITALISATION DE JOUR PSYCHIATRIE ADULTE...</td>\n",
       "      <td>34150 GIGNAC</td>\n",
       "      <td>13.0</td>\n",
       "      <td>RTE</td>\n",
       "      <td>DE MONTPELLIER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>340020312</td>\n",
       "      <td>HJ PSY ADULTES CATTP LES 2 LIONS</td>\n",
       "      <td>HOSPIT DE JOUR PSYCHIATRIE ADULTES SITE PERE S...</td>\n",
       "      <td>34090 MONTPELLIER</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>AV</td>\n",
       "      <td>DU PERE SOULAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>340020346</td>\n",
       "      <td>HJ PSY ADULTES CMP CATTP CHAMPOLLION</td>\n",
       "      <td>CMP HOSPIT DE JOUR PSYCHIATRIE ADULTES CHAMPOL...</td>\n",
       "      <td>34970 LATTES</td>\n",
       "      <td>55.0</td>\n",
       "      <td>R</td>\n",
       "      <td>DU MISTRAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>340020353</td>\n",
       "      <td>HJ PSY ADULTE LE CLOS DU MOULIN MEZE</td>\n",
       "      <td>HJ PSYCHIATRIE ADULTES LE CLOS DU MOULIN MEZE</td>\n",
       "      <td>34140 MEZE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AV</td>\n",
       "      <td>DU MARECHAL LECLERC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>340021286</td>\n",
       "      <td>HJ PSY ADULTES NEW FRESCO COLOMBIERE</td>\n",
       "      <td>HJ PSY ADULTES NEW FRESCO CH COLOMBIERE</td>\n",
       "      <td>34090 MONTPELLIER</td>\n",
       "      <td>39.0</td>\n",
       "      <td>AV</td>\n",
       "      <td>CHARLES FLAHAULT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>340021294</td>\n",
       "      <td>HJ PIJ VILLA LES 2 RUISSEAUX MTP</td>\n",
       "      <td>HJ PSY INFANTO JUVENILE VILLA LES 2 RUISSEAUX MTP</td>\n",
       "      <td>34070 MONTPELLIER</td>\n",
       "      <td>116.0</td>\n",
       "      <td>IMP</td>\n",
       "      <td>DES 2 RUISSEAUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>340021302</td>\n",
       "      <td>HJ PIJ VILLA ST GEORGES MTP</td>\n",
       "      <td>HJ PSY INFANTO JUVENILE VILLA SAINT GEORGES MTP</td>\n",
       "      <td>34070 MONTPELLIER</td>\n",
       "      <td>732.0</td>\n",
       "      <td>AV</td>\n",
       "      <td>DU PAS DU LOUP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>340787084</td>\n",
       "      <td>HJ PSY ADULTE LUNEL</td>\n",
       "      <td>HJ PSY ADULTES ARTISANAT UNITE LUNEL</td>\n",
       "      <td>34400 LUNEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>DE L'ARTISANAT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145</td>\n",
       "      <td>2.634002e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>340787092</td>\n",
       "      <td>HJ PSY ADULTE LA CLARTE</td>\n",
       "      <td>HJ PSYE ADULTES LA CLARTE POMPIGNANE</td>\n",
       "      <td>34000 MONTPELLIER</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>AV</td>\n",
       "      <td>DE LA POMPIGNANE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172</td>\n",
       "      <td>2.634002e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>590006060</td>\n",
       "      <td>HJ PSY ADULTES HAUBOURDIN 59G08</td>\n",
       "      <td>HOPITAL DE JOUR PSY. ADULTES A HAUBOURDIN</td>\n",
       "      <td>59320 HAUBOURDIN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>R</td>\n",
       "      <td>AUGUSTE POTIÉ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>286</td>\n",
       "      <td>2.659067e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>590813374</td>\n",
       "      <td>HJ PSY ENFANTS MOZAIQUE CHR LILLE</td>\n",
       "      <td>HOPITAL DE JOUR PSYCHIATRIQUE POUR ENFANTS DU ...</td>\n",
       "      <td>59000 LILLE</td>\n",
       "      <td>41.0</td>\n",
       "      <td>R</td>\n",
       "      <td>VAN HENDU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350</td>\n",
       "      <td>2.659067e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Numéro FINESS ET nofinesset                     Raison sociale rs  \\\n",
       "133                   300016680   HJ PSY INF JUV CMPEA OUEST MONTAURY   \n",
       "134                   300016698          HJ PSY INF JUV CMPEA VAUVERT   \n",
       "135                   300017910             HJ PSY ADULTES BOURDALOUE   \n",
       "144                   300782166    HJ PSY INF JUV CMPEA EST PELLECUER   \n",
       "148                   310014899  HJ PIJ JARRIGE PETITS GRAVE CHU TLSE   \n",
       "151                   310019617        HJ PIJ ENFANTS PURPAN CHU TLSE   \n",
       "152                   310019625      HJ PIJ ADOS APJA PURPAN CHU TLSE   \n",
       "154                   310025077  HJ PSY GEN BOURGEOIS PURPAN CHU TLSE   \n",
       "187                   340020304           HJ PSY ADULTES UNITE GIGNAC   \n",
       "188                   340020312      HJ PSY ADULTES CATTP LES 2 LIONS   \n",
       "189                   340020346  HJ PSY ADULTES CMP CATTP CHAMPOLLION   \n",
       "190                   340020353  HJ PSY ADULTE LE CLOS DU MOULIN MEZE   \n",
       "192                   340021286  HJ PSY ADULTES NEW FRESCO COLOMBIERE   \n",
       "193                   340021294      HJ PIJ VILLA LES 2 RUISSEAUX MTP   \n",
       "194                   340021302           HJ PIJ VILLA ST GEORGES MTP   \n",
       "207                   340787084                   HJ PSY ADULTE LUNEL   \n",
       "208                   340787092               HJ PSY ADULTE LA CLARTE   \n",
       "376                   590006060       HJ PSY ADULTES HAUBOURDIN 59G08   \n",
       "390                   590813374     HJ PSY ENFANTS MOZAIQUE CHR LILLE   \n",
       "\n",
       "                        Raison sociale longue rslongue  \\\n",
       "133  HJ PSY INFANTO JUVENILE ET CMPEA OUEST MONTAUR...   \n",
       "134              HJ PSY INFANTO JUVENILE CMPEA VAUVERT   \n",
       "135                HJ PSY ADULTES BOURDALOUE CHU NIMES   \n",
       "144  HJ PSY INFANTO JUVENILE CMPEA EST PELLECUER CH...   \n",
       "148        HJ PIJ JARRIGE PETITS LA GRAVE CHU TOULOUSE   \n",
       "151                 HJ PIJ ENFANTS PURPAN CHU TOULOUSE   \n",
       "152        HJ PIJ ADOLESCENTS APJA PURPAN CHU TOULOUSE   \n",
       "154      HJ PSY GENERALE BOURGEOIS PURPAN CHU TOULOUSE   \n",
       "187  CMP HOSPITALISATION DE JOUR PSYCHIATRIE ADULTE...   \n",
       "188  HOSPIT DE JOUR PSYCHIATRIE ADULTES SITE PERE S...   \n",
       "189  CMP HOSPIT DE JOUR PSYCHIATRIE ADULTES CHAMPOL...   \n",
       "190      HJ PSYCHIATRIE ADULTES LE CLOS DU MOULIN MEZE   \n",
       "192            HJ PSY ADULTES NEW FRESCO CH COLOMBIERE   \n",
       "193  HJ PSY INFANTO JUVENILE VILLA LES 2 RUISSEAUX MTP   \n",
       "194    HJ PSY INFANTO JUVENILE VILLA SAINT GEORGES MTP   \n",
       "207               HJ PSY ADULTES ARTISANAT UNITE LUNEL   \n",
       "208               HJ PSYE ADULTES LA CLARTE POMPIGNANE   \n",
       "376          HOPITAL DE JOUR PSY. ADULTES A HAUBOURDIN   \n",
       "390  HOPITAL DE JOUR PSYCHIATRIQUE POUR ENFANTS DU ...   \n",
       "\n",
       "    Ligne d’acheminement (CodePostal+Lib commune) ligneacheminement  \\\n",
       "133                                        30900 NIMES                \n",
       "134                                      30600 VAUVERT                \n",
       "135                                        30000 NIMES                \n",
       "144                                30006 NIMES CEDEX 4                \n",
       "148                             31059 TOULOUSE CEDEX 9                \n",
       "151                             31052 TOULOUSE CEDEX 3                \n",
       "152                                     31000 TOULOUSE                \n",
       "154                             31059 TOULOUSE CEDEX 9                \n",
       "187                                       34150 GIGNAC                \n",
       "188                                  34090 MONTPELLIER                \n",
       "189                                       34970 LATTES                \n",
       "190                                         34140 MEZE                \n",
       "192                                  34090 MONTPELLIER                \n",
       "193                                  34070 MONTPELLIER                \n",
       "194                                  34070 MONTPELLIER                \n",
       "207                                        34400 LUNEL                \n",
       "208                                  34000 MONTPELLIER                \n",
       "376                                   59320 HAUBOURDIN                \n",
       "390                                        59000 LILLE                \n",
       "\n",
       "     Numéro de voie numvoie Type de voie typvoie Libellé de voie voie  \\\n",
       "133                     3.0                    R          DE MONTAURY   \n",
       "134                    28.0                    R     SALVADOR ALLENDE   \n",
       "135                     1.0                    R           BOURDALOUE   \n",
       "144                     NaN                    R      CITE PAUL GIRAN   \n",
       "148                     NaN                   PL                LANGE   \n",
       "151                     NaN                   PL                LANGE   \n",
       "152                     NaN                   PL         DU DR BAYLAC   \n",
       "154                   330.0                   AV   DE GRANDE BRETAGNE   \n",
       "187                    13.0                  RTE       DE MONTPELLIER   \n",
       "188                  1490.0                   AV       DU PERE SOULAS   \n",
       "189                    55.0                    R           DU MISTRAL   \n",
       "190                     NaN                   AV  DU MARECHAL LECLERC   \n",
       "192                    39.0                   AV     CHARLES FLAHAULT   \n",
       "193                   116.0                  IMP      DES 2 RUISSEAUX   \n",
       "194                   732.0                   AV       DU PAS DU LOUP   \n",
       "207                     NaN                    R       DE L'ARTISANAT   \n",
       "208                  1065.0                   AV     DE LA POMPIGNANE   \n",
       "376                    80.0                    R        AUGUSTE POTIÉ   \n",
       "390                    41.0                    R            VAN HENDU   \n",
       "\n",
       "    Complément de voie compvoie Lieu-dit / BP lieuditbp  Code Commune commune  \\\n",
       "133                         NaN                     NaN                   189   \n",
       "134                         NaN                     NaN                   341   \n",
       "135                         NaN                     NaN                   189   \n",
       "144                         NaN                     NaN                   189   \n",
       "148                         NaN               TSA 60033                   555   \n",
       "151                         NaN                     NaN                   555   \n",
       "152                         NaN                     NaN                   555   \n",
       "154                         NaN               TSA 70034                   555   \n",
       "187                         NaN                     NaN                   114   \n",
       "188                         NaN                     NaN                   172   \n",
       "189                         NaN                     NaN                   129   \n",
       "190                         NaN                     NaN                   157   \n",
       "192                         NaN                     NaN                   172   \n",
       "193                         NaN                     NaN                   172   \n",
       "194                         NaN                     NaN                   172   \n",
       "207                         NaN                     NaN                   145   \n",
       "208                         NaN                     NaN                   172   \n",
       "376                         NaN                     NaN                   286   \n",
       "390                         NaN                     NaN                   350   \n",
       "\n",
       "     Numéro de SIRET siret  \n",
       "133           2.630000e+13  \n",
       "134           5.091211e+13  \n",
       "135                    NaN  \n",
       "144           2.630000e+13  \n",
       "148           8.151587e+13  \n",
       "151           2.631001e+13  \n",
       "152           2.631001e+13  \n",
       "154           2.631001e+13  \n",
       "187                    NaN  \n",
       "188                    NaN  \n",
       "189                    NaN  \n",
       "190                    NaN  \n",
       "192                    NaN  \n",
       "193                    NaN  \n",
       "194                    NaN  \n",
       "207           2.634002e+13  \n",
       "208           2.634002e+13  \n",
       "376           2.659067e+13  \n",
       "390           2.659067e+13  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2[\"Raison sociale rs\"].apply(lambda x:x[0:3]==\"HJ \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['Numéro FINESS ET nofinesset'] == \"750000549\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_ORGA = \"http://185.161.45.213/organizations\"\n",
    "def match(siren):\n",
    "\n",
    "    r_post = requests.post(APP_ORGA + \"/organizations/_update\", headers=header, \n",
    "                json = {\"id\": siren})\n",
    "    return r_post.json().get('internal_id')\n",
    "\n",
    "def get(siren):\n",
    "\n",
    "    r = requests.get(APP_ORGA + \"/organizations/\"+siren, headers=header)\n",
    "    return r.json()\n",
    "\n",
    "def update(siren):\n",
    "\n",
    "    r_post = requests.post(APP_ORGA + \"/organizations/_update\", headers=header, \n",
    "                json = {\"id\": siren, \"upsert\": True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(e):\n",
    "    for n in e.get('names', []):\n",
    "        if n.get('status') == 'main':\n",
    "            name_fr = n.get('name_fr')\n",
    "            name_en = n.get('name_en')\n",
    "            if name_fr:\n",
    "                return name_fr\n",
    "            if name_en:\n",
    "                return name_en\n",
    "        \n",
    "    for n in e.get('names', []):\n",
    "        if n.get('status') == 'valid':\n",
    "            name_fr = n.get('name_fr')\n",
    "            name_en = n.get('name_en')\n",
    "            if name_fr:\n",
    "                return name_fr\n",
    "            if name_en:\n",
    "                return name_en\n",
    "        \n",
    "    return None\n",
    "\n",
    "def get_acronym(e):\n",
    "    for n in e.get('acronyms', []):\n",
    "        if n.get('status') == 'main':\n",
    "            name_fr = n.get('acronym_fr')\n",
    "            name_en = n.get('acronym_en')\n",
    "            if name_fr:\n",
    "                return name_fr\n",
    "            if name_en:\n",
    "                return name_en\n",
    "        \n",
    "    for n in e.get('names', []):\n",
    "        if n.get('status') == 'valid':\n",
    "            name_fr = n.get('acronym_fr')\n",
    "            name_en = n.get('acronym_en')\n",
    "            if name_fr:\n",
    "                return name_fr\n",
    "            if name_en:\n",
    "                return name_en\n",
    "        \n",
    "    return None\n",
    "\n",
    "def get_web(e):\n",
    "    for n in e.get('websites', []):\n",
    "        if n.get('status') == 'main':\n",
    "            return n.get('url')\n",
    "        \n",
    "    for n in e.get('names', []):\n",
    "        if n.get('status') == 'valid':\n",
    "            return n.get('url')\n",
    "        \n",
    "    return None\n",
    "\n",
    "def get_address(e):\n",
    "    for n in e.get('addresses', []):\n",
    "        if n.get('status') == 'main':\n",
    "            return n\n",
    "        \n",
    "    for n in e.get('addresses', []):\n",
    "        if n.get('status') == 'valid':\n",
    "            return n\n",
    "        \n",
    "    return {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = {}\n",
    "\n",
    "header = {'Authorization': 'Basic cm9vdDp0b25uZXJyZTJCcmVzdA=='}\n",
    "for i, row in df2.iterrows():\n",
    "    local_id = \"finess{}\".format(row[\"Numéro FINESS ET nofinesset\"])\n",
    "    internal_id = None\n",
    "    siret = None\n",
    "    \n",
    "    if str(row['Raison sociale longue rslongue'])[0:3] == \"HJ \" or \\\n",
    "    str(row['Raison sociale rs'])[0:3] == \"HJ \":\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    if not pd.isnull(row['Numéro de SIRET siret']):\n",
    "        siret = str(row['Numéro de SIRET siret']).replace('.0', '')\n",
    "        local_id = \"siret{}\".format(siret)\n",
    "        internal_id = match(siret)\n",
    "        \n",
    "    if local_id not in my_list:\n",
    "        my_list[local_id] = []\n",
    "        \n",
    "    if internal_id:\n",
    "        dataesr_elt = get(internal_id)\n",
    "        e = {}\n",
    "        e['dataesr_name'] = get_name(dataesr_elt)\n",
    "        e['dataesr_acronym'] = get_acronym(dataesr_elt)\n",
    "        e['dataesr_id'] = internal_id\n",
    "        e['dataesr_website'] = get_web(dataesr_elt)\n",
    "        dataesr_address = get_address(dataesr_elt)\n",
    "        e['dataesr_city'] = dataesr_address.get('city')\n",
    "        e['dataesr_post_code'] = dataesr_address.get('post_code')\n",
    "        e['dataesr_address'] = dataesr_address.get('input_address')\n",
    "        my_list[local_id].append(e)\n",
    "        \n",
    "        \n",
    "    my_list[local_id].append(json.loads(row.to_json()))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "siret26010010200011 1\n",
      "siret26010013600019 1\n",
      "siret26010020100052 1\n",
      "siret26040002300040 1\n",
      "siret26040015500040 1\n",
      "siret26040011400013 1\n",
      "siret26040012200057 1\n",
      "siret26050003800013 1\n",
      "siret78292123300014 4\n",
      "siret26060010100018 1\n",
      "siret26060002800013 1\n",
      "siret26060006900017 1\n",
      "siret26060011900010 1\n",
      "siret26060013500057 1\n",
      "siret78259658900013 2\n",
      "siret26060331100010 1\n",
      "siret26060331100051 1\n",
      "siret26060070500081 1\n",
      "siret26060070500016 1\n",
      "siret26060070500099 4\n",
      "siret78259658900062 1\n",
      "siret26060070500297 1\n",
      "siret26060070500073 2\n",
      "siret26060070500024 1\n",
      "siret26060070500123 1\n",
      "siret26060070500107 1\n",
      "siret26070021600013 1\n",
      "siret26070025700017 1\n",
      "siret20001167400013 1\n",
      "siret26070006700010 1\n",
      "siret26070011700013 1\n",
      "siret26070010900010 1\n",
      "siret26070019000010 1\n",
      "siret26070015800017 1\n",
      "siret26070018200017 1\n",
      "siret26090001400010 1\n",
      "siret26090010500016 1\n",
      "siret26100736300011 1\n",
      "siret26100004600019 1\n",
      "siret26120012500019 1\n",
      "siret20001813300013 1\n",
      "siret26120013300013 1\n",
      "siret26120648600019 1\n",
      "siret20001124500012 1\n",
      "siret26130008100096 16\n",
      "siret26130008100153 4\n",
      "siret26130008100088 2\n",
      "siret26130008100138 2\n",
      "siret26130008100120 1\n",
      "siret15100002300300 1\n",
      "siret26130008100393 1\n",
      "siret26130008100484 2\n",
      "siret26140093100018 2\n",
      "siret78070959800012 2\n",
      "siret26140093100034 1\n",
      "finess140028044 1\n",
      "finess140030891 1\n",
      "finess140032707 1\n",
      "siret26160026600017 1\n",
      "siret26170037100014 1\n",
      "siret26170030600069 1\n",
      "siret26180020500013 1\n",
      "siret26190280300012 1\n",
      "finess190013235 1\n",
      "finess210006938 1\n",
      "finess210012464 1\n",
      "siret22210001800134 1\n",
      "siret26210007600070 1\n",
      "siret26210007600013 4\n",
      "siret26210008400017 1\n",
      "siret26210002700016 1\n",
      "siret77820427100010 2\n",
      "finess230004897 1\n",
      "siret26240562400012 1\n",
      "siret26240570700015 1\n",
      "siret26240571500018 1\n",
      "siret26240587100019 1\n",
      "siret20005293400011 1\n",
      "siret26240588900011 1\n",
      "siret20005293400029 1\n",
      "siret26250176000017 2\n",
      "siret26250411100010 1\n",
      "siret26250047300018 1\n",
      "siret26250434300019 1\n",
      "siret26250176000066 2\n",
      "siret26250176000231 1\n",
      "siret26260007500010 1\n",
      "siret26260001800010 1\n",
      "siret26420030400832 1\n",
      "siret26270285500012 1\n",
      "siret26270286300065 1\n",
      "siret26270289700014 1\n",
      "siret26280090700012 1\n",
      "siret20002305900021 2\n",
      "siret20002305900039 1\n",
      "siret26290010300017 1\n",
      "siret26290012900012 1\n",
      "siret15100002300136 1\n",
      "siret26290011100028 1\n",
      "siret20002305900112 2\n",
      "siret20002305900054 1\n",
      "siret20002305900047 1\n",
      "siret20002305900252 1\n",
      "siret20002305900088 1\n",
      "siret20002305900294 2\n",
      "finess290034917 1\n",
      "finess290034925 1\n",
      "finess290034958 1\n",
      "finess290034966 1\n",
      "finess290034974 1\n",
      "finess290034982 1\n",
      "finess290034990 1\n",
      "finess290035054 1\n",
      "finess290036334 1\n",
      "finess290036722 1\n",
      "finess290036755 1\n",
      "siret26200007800010 1\n",
      "siret26201015000015 1\n",
      "siret20001124500038 1\n",
      "siret26300004400093 1\n",
      "siret26300014300119 1\n",
      "siret26300015000015 1\n",
      "finess300018231 1\n",
      "finess300018249 1\n",
      "finess300018256 1\n",
      "finess300019395 1\n",
      "finess300019437 1\n",
      "siret26300003600032 2\n",
      "siret26300003600255 1\n",
      "siret26300003600107 1\n",
      "siret26310011700013 1\n",
      "siret26310012500016 2\n",
      "siret26310060400010 1\n",
      "siret26310012500511 1\n",
      "siret26310012500529 1\n",
      "siret26310012500594 1\n",
      "siret26310012500628 1\n",
      "siret26310012500032 1\n",
      "siret77692637000037 2\n",
      "siret26310012500040 2\n",
      "siret26310012500057 2\n",
      "siret26310012500065 1\n",
      "siret26310012500180 2\n",
      "siret20002275400010 1\n",
      "siret26320008100010 1\n",
      "siret20001324100019 1\n",
      "siret26320012300010 1\n",
      "siret26320013100013 1\n",
      "siret26320014900015 1\n",
      "siret26320019800061 1\n",
      "siret78183171400014 2\n",
      "finess330781303 1\n",
      "siret26330582300449 1\n",
      "siret26330582300076 1\n",
      "siret26330582300035 2\n",
      "siret26330582300092 2\n",
      "siret26330582300068 1\n",
      "siret26340007900012 1\n",
      "siret26340008700015 1\n",
      "siret26340016000382 2\n",
      "siret78821496300035 1\n",
      "siret26340014500011 1\n",
      "siret26340015200017 1\n",
      "siret26340012900015 1\n",
      "siret26340016000408 4\n",
      "siret26340016000085 4\n",
      "siret26340008700056 1\n",
      "siret26340016000127 2\n",
      "finess340021260 1\n",
      "siret26340016000440 1\n",
      "siret26340016000432 1\n",
      "finess340025238 1\n",
      "finess340025246 1\n",
      "finess340025279 1\n",
      "finess340027739 1\n",
      "siret26340010300010 1\n",
      "siret26340016000036 2\n",
      "siret26340016000226 1\n",
      "siret26340016000010 2\n",
      "siret26350001900017 1\n",
      "siret26350011800017 1\n",
      "siret26350009200014 1\n",
      "siret26350003500013 1\n",
      "siret26350002700010 1\n",
      "siret26350007600017 4\n",
      "siret77773916000011 2\n",
      "siret26350007600165 1\n",
      "siret26350007600025 2\n",
      "finess350040499 1\n",
      "finess350051470 1\n",
      "finess350053013 1\n",
      "siret26360013200017 1\n",
      "siret26360002500013 1\n",
      "siret26360005800014 1\n",
      "siret26360010800017 1\n",
      "siret26370018900024 2\n",
      "siret26370018900032 1\n",
      "siret26370018900016 2\n",
      "siret26370014800111 1\n",
      "siret26370018900479 1\n",
      "siret26370018900131 1\n",
      "siret26370018900107 1\n",
      "siret26370018900222 2\n",
      "siret26370018900073 1\n",
      "siret26370018900115 1\n",
      "siret26370018900149 1\n",
      "siret26370018900370 1\n",
      "siret26370018900453 1\n",
      "siret26370018900206 1\n",
      "siret26380030200014 2\n",
      "siret26380022900019 1\n",
      "siret26380003900012 1\n",
      "siret26380029400013 1\n",
      "siret26380014600015 1\n",
      "siret26380030200469 1\n",
      "siret26380030200402 1\n",
      "siret26380030200394 1\n",
      "siret26380030200477 1\n",
      "siret26380030200030 2\n",
      "siret26410013200010 1\n",
      "siret26410010800044 1\n",
      "siret26410015700017 1\n",
      "siret26420039500012 1\n",
      "siret26420008000028 1\n",
      "siret26420028800019 1\n",
      "siret26420009800012 1\n",
      "siret26420023900012 1\n",
      "siret26420003100062 1\n",
      "siret26420030400618 1\n",
      "siret26420030400592 1\n",
      "finess420013187 1\n",
      "siret26420030400840 1\n",
      "siret26420041100017 1\n",
      "siret26420030400022 1\n",
      "siret26420030400063 2\n",
      "siret26420030400030 2\n",
      "siret26440013600018 4\n",
      "siret26440013600711 1\n",
      "siret26440306400084 1\n",
      "siret26440007800012 1\n",
      "siret26440306400092 1\n",
      "siret53225430700020 2\n",
      "siret26440310600018 1\n",
      "siret26440310600026 1\n",
      "siret26440304900044 1\n",
      "siret26440304900077 1\n",
      "siret26440029200019 1\n",
      "siret26440005200017 1\n",
      "siret26440013600026 2\n",
      "siret26440013600422 1\n",
      "siret26440013600075 1\n",
      "siret26440013600133 1\n",
      "siret26440013600463 1\n",
      "siret26440013600638 1\n",
      "siret26440013600596 1\n",
      "siret26440013600653 1\n",
      "siret26440013600612 1\n",
      "siret26440013600588 1\n",
      "siret26440013600620 1\n",
      "siret26440013600604 1\n",
      "siret26440013600646 1\n",
      "siret26440013600661 1\n",
      "siret26440013600679 1\n",
      "finess440050458 1\n",
      "finess440050466 1\n",
      "finess440055747 1\n",
      "siret26450009100014 1\n",
      "siret26450001800017 1\n",
      "siret26450014100017 2\n",
      "siret26450007500017 1\n",
      "siret26450025700011 1\n",
      "siret26450009100030 2\n",
      "siret26450009100212 1\n",
      "siret26450009100337 1\n",
      "siret26460017200011 1\n",
      "siret26470348900049 1\n",
      "siret26470349700018 1\n",
      "siret26470249900023 1\n",
      "siret26330582300506 1\n",
      "siret26480012900027 1\n",
      "siret26480004600015 1\n",
      "siret26480008700019 1\n",
      "siret26480005300011 1\n",
      "siret26490003600015 2\n",
      "siret53225430700012 2\n",
      "siret26490664500017 1\n",
      "siret26490664500058 1\n",
      "siret26490008500012 1\n",
      "siret26490048100013 1\n",
      "siret26490049900015 1\n",
      "siret26490046500016 1\n",
      "siret26490667800042 1\n",
      "siret26490667800075 1\n",
      "finess490020971 1\n",
      "siret26490003600106 1\n",
      "siret26500101600012 1\n",
      "siret26500103200019 1\n",
      "siret26500106500019 1\n",
      "siret26500109900018 1\n",
      "siret78070959800020 1\n",
      "siret26510004000012 1\n",
      "siret78042143400017 2\n",
      "siret26510005700180 2\n",
      "siret26510005700040 1\n",
      "siret26510005700032 2\n",
      "siret26510005700065 1\n",
      "finess510025380 1\n",
      "siret26520002200019 1\n",
      "siret26520006300013 1\n",
      "siret26520010500012 1\n",
      "siret26520015400010 1\n",
      "siret26530333900013 1\n",
      "siret26530014500017 1\n",
      "siret26530015200013 1\n",
      "siret26530333900054 1\n",
      "siret26530036800015 1\n",
      "siret26530333900021 1\n",
      "siret20004216600112 1\n",
      "siret26540648800022 1\n",
      "siret20004216600179 1\n",
      "siret26540006900018 1\n",
      "siret20004216600013 2\n",
      "siret78333606800029 2\n",
      "siret20004216600161 2\n",
      "siret20004216600047 1\n",
      "siret20004216600039 1\n",
      "siret20004216600088 1\n",
      "siret20004216600021 1\n",
      "siret26560034600018 1\n",
      "siret26560017100010 1\n",
      "siret26560043700015 1\n",
      "siret26570280300528 1\n",
      "siret26570280300346 1\n",
      "siret15100002300219 1\n",
      "siret26570015300017 1\n",
      "siret26570280300411 1\n",
      "siret26570280300031 1\n",
      "siret26570280300486 1\n",
      "finess570026575 1\n",
      "siret26570280300510 2\n",
      "siret26580011000016 1\n",
      "siret26590671900017 4\n",
      "siret78369734500016 2\n",
      "siret26590671900389 2\n",
      "finess590048468 1\n",
      "finess590060901 1\n",
      "finess590062279 1\n",
      "siret26590671900058 2\n",
      "siret26590671900116 1\n",
      "siret26590671900181 2\n",
      "siret26590671900165 1\n",
      "siret26590671900124 2\n",
      "siret26590671900157 1\n",
      "siret26590671900173 2\n",
      "siret26590671900322 2\n",
      "siret26590671900348 1\n",
      "siret26600703800018 1\n",
      "siret26600024900018 1\n",
      "siret26750045200714 1\n",
      "siret26610054400011 1\n",
      "siret26610055100016 1\n",
      "siret26610056900018 1\n",
      "siret26620938600017 1\n",
      "siret26750045200755 1\n",
      "siret26630746100019 2\n",
      "siret77921386700020 2\n",
      "siret26630746100050 2\n",
      "siret26630746100308 2\n",
      "siret26630746100084 1\n",
      "siret26630746100076 1\n",
      "siret26640550500014 1\n",
      "siret26750045200581 1\n",
      "siret26660007100010 1\n",
      "siret26670057400012 2\n",
      "siret77885330900046 1\n",
      "finess670017979 1\n",
      "finess670018779 1\n",
      "finess670018787 1\n",
      "siret26670057400459 1\n",
      "siret26670057400079 1\n",
      "siret26670057400095 4\n",
      "siret26670057400186 1\n",
      "siret26670057400202 1\n",
      "siret26690022400012 1\n",
      "siret26690009100064 1\n",
      "siret26690018200087 1\n",
      "siret26690021600018 1\n",
      "siret26690005900012 1\n",
      "siret26690004200018 1\n",
      "siret20007689100031 1\n",
      "siret77992413300019 2\n",
      "siret26690027300969 2\n",
      "siret26690027300985 2\n",
      "siret26690027300720 1\n",
      "siret26690027300019 2\n",
      "siret26690027300993 1\n",
      "siret26690027301033 1\n",
      "siret43218235000020 1\n",
      "siret26690027301058 1\n",
      "finess690042387 1\n",
      "finess690044649 1\n",
      "siret15100002300433 1\n",
      "siret26690027300217 2\n",
      "siret26690027300324 2\n",
      "siret26690027300100 2\n",
      "siret26690027300910 2\n",
      "siret26690027300977 2\n",
      "siret26690027300159 2\n",
      "siret26690027300365 2\n",
      "siret26690027300126 1\n",
      "siret26690027300357 1\n",
      "siret26690027300266 2\n",
      "siret26690027300316 1\n",
      "siret26690027300274 1\n",
      "siret26690027300654 1\n",
      "siret26710006300010 1\n",
      "siret26710014700011 1\n",
      "siret26710025300017 1\n",
      "siret26710030300010 1\n",
      "siret26710046900035 1\n",
      "siret26710014700078 1\n",
      "siret26710023800018 1\n",
      "siret26710045100033 1\n",
      "siret26720020200013 1\n",
      "siret26730014300018 1\n",
      "siret26730009300049 1\n",
      "siret26740008300064 1\n",
      "siret26740017400012 1\n",
      "siret26750045200672 2\n",
      "siret18000702300021 1\n",
      "siret26750045201720 1\n",
      "siret26750045200599 2\n",
      "siret78428191700012 2\n",
      "siret26750045200474 2\n",
      "siret26750045200516 2\n",
      "siret26750045200466 2\n",
      "siret26750045200300 2\n",
      "siret26750045200227 2\n",
      "siret26750045200243 2\n",
      "siret26750045200524 2\n",
      "siret26750045200052 1\n",
      "siret38304765100013 1\n",
      "siret26750045200045 2\n",
      "siret26750045200284 2\n",
      "siret26750045201274 1\n",
      "siret26750045200201 2\n",
      "siret26750045200235 2\n",
      "siret26750045200623 2\n",
      "siret78425716400037 2\n",
      "siret26750045200698 2\n",
      "siret26750045200854 1\n",
      "siret26750045200847 1\n",
      "siret26750045201191 2\n",
      "siret26750045200995 2\n",
      "siret26750045200680 1\n",
      "siret18000702300013 2\n",
      "siret26750045201480 1\n",
      "siret11009001600012 2\n",
      "siret26760162300015 1\n",
      "siret26760163100018 1\n",
      "siret26760166400019 1\n",
      "siret26760168000130 1\n",
      "siret26760168000015 6\n",
      "siret78111289100010 2\n",
      "siret26760169800017 1\n",
      "siret26760174800010 1\n",
      "siret26760168000023 1\n",
      "siret26760168000049 1\n",
      "siret26780234600010 1\n",
      "siret20003030200018 1\n",
      "siret26790040500015 1\n",
      "siret26800014800018 2\n",
      "siret26800014800059 1\n",
      "siret26800014800125 2\n",
      "finess800016735 1\n",
      "siret26800014800356 1\n",
      "siret26820010200013 1\n",
      "siret20002802500019 1\n",
      "siret26750045200342 1\n",
      "siret26690027300399 1\n",
      "siret15100002300276 1\n",
      "siret26830362500019 1\n",
      "siret26840015700049 1\n",
      "siret26840011600011 1\n",
      "siret26840020700042 1\n",
      "siret26850028700019 1\n",
      "siret20005038300013 1\n",
      "siret26850029500012 1\n",
      "siret20005535800028 1\n",
      "siret20005535800010 2\n",
      "siret20005535800044 1\n",
      "siret20005535800051 1\n",
      "siret20005535800069 1\n",
      "siret20005535800036 1\n",
      "siret20005535800077 1\n",
      "siret26870851800017 4\n",
      "siret26870042400057 1\n",
      "siret26870042400099 1\n",
      "siret26872065300073 1\n",
      "siret26870042400065 1\n",
      "siret26870851800058 2\n",
      "siret26870851800355 1\n",
      "siret26870851800314 1\n",
      "finess870017647 1\n",
      "finess870018181 1\n",
      "siret26880022400019 1\n",
      "siret26880023200012 1\n",
      "siret26880747600018 2\n",
      "siret26880021600015 1\n",
      "siret26880019000012 1\n",
      "siret26890030500015 1\n",
      "siret26750045200417 1\n",
      "siret26750045200532 1\n",
      "siret26750045200540 1\n",
      "siret78425716400060 1\n",
      "siret26750045200979 1\n",
      "siret78425716400086 2\n",
      "finess920029758 1\n",
      "siret26750045200375 2\n",
      "siret26750045200391 2\n",
      "siret26750045200094 2\n",
      "siret26750045200383 2\n",
      "siret26750045200573 2\n",
      "siret26750045200409 2\n",
      "siret15100002300631 1\n",
      "siret26750045200458 1\n",
      "siret80803419300017 1\n",
      "siret26750045200367 2\n",
      "siret77574110100056 1\n",
      "siret77574110100031 2\n",
      "siret26750045200730 1\n",
      "siret26750045200433 2\n",
      "siret26750045200557 2\n",
      "siret26750045200425 2\n",
      "siret26750045200441 2\n",
      "siret26750045200110 2\n",
      "siret26750045200292 2\n",
      "siret26750045200664 1\n",
      "siret15100002300649 1\n",
      "siret26750045200953 1\n",
      "siret26750045200649 1\n",
      "siret26971065300016 1\n",
      "siret26971041400013 2\n",
      "siret26971043000076 1\n",
      "finess970112587 1\n",
      "finess970112793 1\n",
      "finess970112835 1\n",
      "finess970112850 1\n",
      "finess970112884 1\n",
      "finess970113007 1\n",
      "siret26972073600033 1\n",
      "finess970211215 1\n",
      "siret20003452800139 1\n",
      "finess970211231 1\n",
      "siret20003452800154 2\n",
      "siret20003452800162 1\n",
      "siret20003452800170 1\n",
      "siret20003452800188 1\n",
      "finess970213278 1\n",
      "finess970213286 1\n",
      "siret20003001300011 2\n",
      "siret20003001300102 2\n",
      "siret20003001300037 1\n",
      "siret20003001300078 1\n",
      "siret20003001300086 1\n",
      "finess970410536 1\n",
      "finess970410544 1\n",
      "finess970410551 1\n",
      "finess970410569 1\n",
      "finess970410577 1\n",
      "finess970410585 1\n",
      "finess970410593 1\n",
      "finess970410601 1\n",
      "finess970410619 1\n",
      "finess970410627 1\n",
      "finess970410635 1\n",
      "finess970410643 1\n",
      "siret20003001300144 1\n"
     ]
    }
   ],
   "source": [
    "for k in my_list:\n",
    "    print(k, len(my_list[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(my_list, open(\"../project/server/main/dict_finess.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finess = pickle.load(open(\"dict_finess.pkl\", \"rb\"))\n",
    "len(finess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accents(w: str) -> str:\n",
    "    \"\"\"Normalize accents and stuff in string.\"\"\"\n",
    "    w2 = w.replace(\"’\", \" \")\n",
    "    return \"\".join(\n",
    "      c for c in unicodedata.normalize(\"NFD\", w2)\n",
    "      if unicodedata.category(c) != \"Mn\")\n",
    "\n",
    "\n",
    "def delete_punct(w: str) -> str:\n",
    "    \"\"\"Delete all puctuation in a string.\"\"\"\n",
    "    return w.lower().translate(\n",
    "          str.maketrans(string.punctuation, len(string.punctuation)*\" \"))\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"Normalize string. Delete puctuation and accents.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        text = delete_punct(text)\n",
    "        text = strip_accents(text)\n",
    "        text = text.replace('\\xa0', ' ')\n",
    "        text = \" \".join(text.split())\n",
    "    return text or \"\"\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    return normalize_text(text).lower().replace('-', ' ')\\\n",
    "              .replace('‐', ' ').replace('  ', ' ')\n",
    "\n",
    "def get_common_words(finess, field, split=True, threshold = 10):\n",
    "    common = {}\n",
    "    for elt in finess:\n",
    "\n",
    "        if split:\n",
    "            v = normalize(elt.get(field, '')).split(' ')\n",
    "        else:\n",
    "            v = [normalize(elt.get(field, ''))]\n",
    "        for w in v:\n",
    "            if w not in common:\n",
    "                common[w] = 0\n",
    "            common[w] += 1\n",
    "\n",
    "        \n",
    "    result = []\n",
    "    for w in common:\n",
    "        if common[w] > threshold:\n",
    "            result.append(w)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_to_index = []\n",
    "for k in finess:\n",
    "    new_elt = {\"name\":[], \"city\":[], \"id\": k}\n",
    "\n",
    "    for elt in finess[k]:\n",
    "\n",
    "        if elt.get('dataesr_city'):\n",
    "            new_elt['city'].append( elt.get('dataesr_city') )\n",
    "        if elt.get('Ligne d’acheminement (CodePostal+Lib commune) ligneacheminement'):\n",
    "            new_elt['city'].append( elt.get('Ligne d’acheminement (CodePostal+Lib commune) ligneacheminement') )\n",
    "\n",
    "        if elt.get('Raison sociale rs'):\n",
    "            new_elt['name'].append(elt.get('Raison sociale rs'))\n",
    "        if elt.get('Raison sociale longue rslongue'):\n",
    "            new_elt['name'].append(elt.get('Raison sociale longue rslongue'))\n",
    "        if elt.get('dataesr_name'):\n",
    "            new_elt['name'].append(elt.get('dataesr_name'))\n",
    "            \n",
    "            \n",
    "    docs_to_index.append(new_elt)\n",
    "    \n",
    "len(docs_to_index)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_cities = []\n",
    "for k in finess:\n",
    "    for elt in finess[k]:\n",
    "        if elt.get('dataesr_city'):\n",
    "            known_cities.append(normalize(elt.get('dataesr_city')))\n",
    "        if elt.get('Ligne d’acheminement (CodePostal+Lib commune) ligneacheminement'):\n",
    "            known_cities.append(normalize(elt.get('Ligne d’acheminement (CodePostal+Lib commune) ligneacheminement')))\n",
    "known_cities = list(set(known_cities) - set('france'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## docker-compose -f docker-compose.local.yml up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(['localhost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_cities = [c for c in get_common_words(finess, 'city',split=True, threshold=0) if len(c)>2]\n",
    "#main_cities = list(set(main_cities) - set(['france']))\n",
    "#main_names = list(set(get_common_words(finess, 'name',5)) - set(main_cities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_remove = [\"france\"]#\"hopital\", \"hospitalier\", \"service\", \"centre\", \"universitaire\", \"regional\", \"saint\",\n",
    "                  #\"chu\", \"chr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-1419897142cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'main_names' is not defined"
     ]
    }
   ],
   "source": [
    "main_names[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_filters():\n",
    "    char_filters =  {}\n",
    "    char_filters[\"keep_digits_only\"] = {\n",
    "          \"type\": \"pattern_replace\",\n",
    "          \"pattern\": \"\\D+\",\n",
    "          \"replacement\": \" \"\n",
    "        }\n",
    "    char_filters[\"remove_digits\"] = {\n",
    "          \"type\": \"pattern_replace\",\n",
    "          \"pattern\": \"[0-9]\",\n",
    "          \"replacement\": \" \"\n",
    "        }\n",
    "    char_filters[\"remove_space\"] = {\n",
    "          \"type\": \"pattern_replace\",\n",
    "          \"pattern\": \" |_\",\n",
    "          \"replacement\": \"\"\n",
    "        }\n",
    "    return char_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filters(main_cities, main_names):\n",
    "    filters = {}\n",
    "    filters[\"keep_cities\"]= {\n",
    "      \"type\": \"keep\",\n",
    "      \"keep_words\": main_cities\n",
    "    }\n",
    "    filters[\"city_remover\"]= {\n",
    "        \"type\": \"stop\",\n",
    "        \"ignore_case\": True,\n",
    "        \"stopwords\": main_cities\n",
    "      }\n",
    "    filters[\"common_names_filter\"]= {\n",
    "        \"type\": \"stop\",\n",
    "        \"ignore_case\": True,\n",
    "        \"stopwords\": main_names\n",
    "      }\n",
    "    filters[\"french_stop\"] = {\n",
    "              \"type\":       \"stop\",\n",
    "              \"stopwords\":  \"_french_\" \n",
    "    }\n",
    "    filters[\"english_stop\"] = {\n",
    "          \"type\":       \"stop\",\n",
    "          \"stopwords\":  \"_english_\" \n",
    "        }\n",
    "\n",
    "    filters[\"extract_digits\"]={\n",
    "      \"type\": \"keep_types\",\n",
    "      \"types\": [ \"<NUM>\" ]\n",
    "    }\n",
    "\n",
    "    filters[\"length_min_2_char\"]= {\n",
    "          \"type\": \"length\",\n",
    "          \"min\": 2\n",
    "        }\n",
    "\n",
    "    filters[\"length_min_3_char\"]= {\n",
    "          \"type\": \"length\",\n",
    "          \"min\": 3\n",
    "        }\n",
    "\n",
    "    filters[\"length_min_4_char\"]= {\n",
    "          \"type\": \"length\",\n",
    "          \"min\": 4\n",
    "        }\n",
    "\n",
    "    filters[\"length_min_5_char\"]= {\n",
    "          \"type\": \"length\",\n",
    "          \"min\": 5\n",
    "        }\n",
    "\n",
    "    filters[\"length_2_5_char\"]= {\n",
    "          \"type\": \"length\",\n",
    "          \"min\": 2,\n",
    "          \"max\": 5\n",
    "        }\n",
    "\n",
    "    filters[\"french_elision\"]= {\n",
    "          \"type\": \"elision\",\n",
    "          \"articles_case\": True,\n",
    "          \"articles\": [\"l\", \"m\", \"t\", \"qu\", \"n\", \"s\", \"j\", \"d\", \"c\", \"jusqu\", \"quoiqu\", \"lorsqu\", \"puisqu\"]\n",
    "        }\n",
    "\n",
    "    filters[\"french_stemmer\"]= {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"light_french\"\n",
    "        }\n",
    "\n",
    "    filters[\"english_stemmer\"]= {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"light_english\"\n",
    "        }\n",
    "\n",
    "    filters[\"underscore_remove\"]= {\n",
    "        \"type\": \"pattern_replace\",\n",
    "        \"pattern\": \"(-|_)\",\n",
    "        \"replacement\": \" \"\n",
    "      }\n",
    "\n",
    "    filters[\"remove_space\"] = {\n",
    "      \"type\": \"pattern_replace\",\n",
    "      \"pattern\": \" \",\n",
    "      \"replacement\": \"\"\n",
    "    }\n",
    "    return filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizers():\n",
    "    tokenizers = {}\n",
    "    tokenizers[\"tokenizer_ngram_3_8\"] = {\n",
    "              \"type\": \"ngram\",\n",
    "              \"min_gram\": 3,\n",
    "              \"max_gram\": 8,\n",
    "              \"token_chars\": [\n",
    "                \"letter\",\n",
    "                \"digit\"\n",
    "              ]\n",
    "            }\n",
    "#tokenizers[\"code_tokenizer\"]= {\n",
    "#          \"type\": \"simple_pattern\",\n",
    "#          \"pattern\": \"([A-Za-z\\-\\_]{1,5})(.{0,1})([0-9]{1,5})\"\n",
    "#        }\n",
    "\n",
    "    tokenizers['code_tokenizer']=  {\n",
    "          \"type\": \"pattern\",\n",
    "          \"pattern\": \"_|\\W+\"\n",
    "        }\n",
    "\n",
    "    tokenizers[\"code_tokenizer_lucky\"]= {\n",
    "          \"type\": \"simple_pattern\",\n",
    "          \"pattern\": \"(UMR|U|FR|EA|UPR|UR|CIC|GDR)(.{0,4})([0-9]{2,4})\"\n",
    "        }\n",
    "    return tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analyzers():\n",
    "\n",
    "    analyzers = {}\n",
    "    analyzers['analyzer_digits'] ={\n",
    "        \"tokenizer\": \"standard\",\n",
    "        \"char_filter\": [\"keep_digits_only\"],\n",
    "        \"filter\": [ \"length_2_5_char\" ]\n",
    "        }\n",
    "\n",
    "        \n",
    "    analyzers[\"analyzer_city\"] = {\n",
    "            \"tokenizer\": \"standard\",\n",
    "            \"char_filter\": [\"remove_digits\"],\n",
    "            \"filter\": [\"lowercase\", \n",
    "                       \"icu_folding\",\n",
    "                       \"keep_cities\"\n",
    "                      ]\n",
    "          }\n",
    "\n",
    "\n",
    "    analyzers[\"analyzer_name\"] =  {\n",
    "            \"tokenizer\": \"icu_tokenizer\",\n",
    "            \"filter\": [\n",
    "                \"french_elision\",\n",
    "                \"icu_folding\",\n",
    "                \"french_stop\",\n",
    "                \"english_stop\",\n",
    "                \"lowercase\",\n",
    "                \"city_remover\",\n",
    "                \"common_names_filter\"\n",
    "            ]\n",
    "          }\n",
    "\n",
    "    return analyzers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_index_finess():\n",
    "    myIndex = 'index-finess'\n",
    "    print(\"deleting \"+myIndex, end=':', flush=True)\n",
    "    del_docs = es.delete_by_query(index=myIndex, body={\"query\": {\"match_all\": {}}})\n",
    "    print(del_docs, flush=True)\n",
    "    del_index = es.indices.delete(index=myIndex, ignore=[400, 404])\n",
    "    print(del_index, flush=True)\n",
    "    return \n",
    "\n",
    "def reset_index_finess(filters, char_filters, tokenizers, analyzers):\n",
    "\n",
    "    myIndex = 'index-finess'\n",
    "    try:\n",
    "        delete_index_finess()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    setting_finess = {\n",
    "        \"index\":{\n",
    "            \"max_ngram_diff\":8\n",
    "        },\n",
    "        \"analysis\": {        \n",
    "            \"char_filter\": char_filters,\n",
    "            \"filter\": filters,\n",
    "            \"analyzer\": analyzers,\n",
    "            \"tokenizer\": tokenizers\n",
    "        }\n",
    "      }\n",
    "    \n",
    "                \n",
    "    mapping_finess={\n",
    "      \"properties\": {\n",
    "        \"name\":    { \n",
    "            \"type\": \"text\",\n",
    "             \"boost\": 5,\n",
    "            \"analyzer\": \"analyzer_name\"\n",
    "        },\n",
    "        \"city\":    { \n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\":\"analyzer_name\",\n",
    "            \n",
    "            \"fields\":{  \n",
    "                  \"digits\":{  \n",
    "                     \"type\":\"text\",\n",
    "                     \"analyzer\":\"analyzer_digits\"\n",
    "                  }\n",
    "                ,\"city\":{  \n",
    "                     \"type\":\"text\",\n",
    "                     \"analyzer\":\"analyzer_city\"\n",
    "                  }\n",
    "            }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    response = es.indices.create(\n",
    "        index=myIndex,\n",
    "        body={\n",
    "            \"settings\": setting_finess,\n",
    "            \"mappings\": mapping_finess\n",
    "            \n",
    "        },\n",
    "        ignore=400 # ignore 400 already exists code\n",
    "    )\n",
    "\n",
    "    if 'acknowledged' in response:\n",
    "        if response['acknowledged'] == True:\n",
    "            print (\"INDEX MAPPING SUCCESS FOR INDEX:\", response['index'], flush=True)\n",
    "            \n",
    "    print(response, flush=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting index-finess:{'error': {'root_cause': [{'type': 'resource_already_exists_exception', 'reason': 'index [index-finess/o09ygPkVTaai2qVt_zYxYw] already exists', 'index_uuid': 'o09ygPkVTaai2qVt_zYxYw', 'index': 'index-finess'}], 'type': 'resource_already_exists_exception', 'reason': 'index [index-finess/o09ygPkVTaai2qVt_zYxYw] already exists', 'index_uuid': 'o09ygPkVTaai2qVt_zYxYw', 'index': 'index-finess'}, 'status': 400}\n"
     ]
    }
   ],
   "source": [
    "filters = get_filters(known_cities, names_to_remove)\n",
    "char_filters = get_char_filters()\n",
    "tokenizers = get_tokenizers()\n",
    "analyzers = get_analyzers()\n",
    "res = {}\n",
    "\n",
    "reset_index_finess(filters, char_filters, tokenizers, analyzers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(578, [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerem/anaconda3/lib/python3.8/site-packages/elasticsearch/connection/base.py:190: ElasticsearchDeprecationWarning: [types removal] Specifying types in bulk requests is deprecated.\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "actions = [\n",
    "{\n",
    "    \"_index\": \"index-finess\",\n",
    "    \"_type\": \"_doc\",\n",
    "    \"_id\": j,\n",
    "    \"_source\": docs_to_index[j] \n",
    "}\n",
    "        for j in range(0, len(docs_to_index))\n",
    "]\n",
    "len(actions)\n",
    "\n",
    "print(helpers.bulk(es, actions), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_for_count(x, matching_field):\n",
    "    \n",
    "    return x.lower()[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(input_str, search_fields, size=20, verbose=False, highlights=[], fuzzy_ok=False):\n",
    "\n",
    "    myIndex = \"index-finess\"\n",
    "    s = Search(using=es, index=myIndex)\n",
    "    for f in highlights:\n",
    "        s = s.highlight(f)\n",
    "\n",
    "\n",
    "    s = s.query(\"multi_match\", query=input_str,\n",
    "            minimum_should_match=1,\n",
    "            fuzziness=\"auto\",\n",
    "            fields=search_fields)\n",
    "\n",
    "    s = s[0:size]\n",
    "    res = s.execute()\n",
    "    hits = res.hits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    id_res=\"\"\n",
    "    if len(hits)>0:\n",
    "        max_score = hits[0].meta.score\n",
    "\n",
    "\n",
    "    res_ids = []\n",
    "    scores = []\n",
    "    highlights={}\n",
    "    nb_matches = {}\n",
    "    matches_frag = {}\n",
    "\n",
    "    for hit in hits:\n",
    "\n",
    "        res_ids.append(hit.id)\n",
    "        scores.append(hit.meta.score)\n",
    "        highlights[hit.id]=[]\n",
    "\n",
    "\n",
    "        for matching_field in hit.meta.highlight:\n",
    "            for fragment in hit.meta.highlight[matching_field]:\n",
    "                highlights[hit.id].append(fragment)\n",
    "\n",
    "                matches = [normalize_for_count(e.get_text(), matching_field) for e in BeautifulSoup(fragment, 'lxml').find_all('em')]\n",
    "\n",
    "\n",
    "                if hit.id not in nb_matches:\n",
    "                    nb_matches[hit.id] = 0\n",
    "                    matches_frag[hit.id] = []\n",
    "                matches_frag[hit.id] += matches\n",
    "                matches_frag[hit.id] = list(set(matches_frag[hit.id]))\n",
    "                nb_matches[hit.id] = len(matches_frag[hit.id])\n",
    "\n",
    "\n",
    "\n",
    "    #print(scores)\n",
    "    return {'ids': res_ids, 'highlights': highlights, 'nb_matches': nb_matches}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_name(x, verbose=False):\n",
    "    return get_info(x, ['name'], size=200, verbose=verbose, highlights=['name'])\n",
    "def get_match_city(x, verbose=False):\n",
    "    return get_info(x, ['city.city'], size=200, verbose=verbose, highlights=['city.city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['siret26130008100096',\n",
       "  'siret26130008100153',\n",
       "  'siret78292123300014',\n",
       "  'siret26130008100088',\n",
       "  'siret26130008100138',\n",
       "  'siret26130008100484',\n",
       "  'siret26130008100120',\n",
       "  'siret15100002300300',\n",
       "  'siret26130008100393'],\n",
       " 'highlights': {'siret26130008100096': ['<em>Marseille</em>',\n",
       "   '<em>Marseille</em>',\n",
       "   '<em>Marseille</em>',\n",
       "   '<em>Marseille</em>',\n",
       "   '<em>Marseille</em>'],\n",
       "  'siret26130008100153': ['<em>Marseille</em>',\n",
       "   '13015 <em>MARSEILLE</em>',\n",
       "   '<em>Marseille</em>',\n",
       "   '13015 <em>MARSEILLE</em>'],\n",
       "  'siret78292123300014': ['<em>Marseille</em>',\n",
       "   '<em>Marseille</em>',\n",
       "   '13273 <em>MARSEILLE</em> CEDEX 09'],\n",
       "  'siret26130008100088': ['<em>Marseille</em>', '13005 <em>MARSEILLE</em>'],\n",
       "  'siret26130008100138': ['<em>Marseille</em>',\n",
       "   '13274 <em>MARSEILLE</em> CEDEX 09'],\n",
       "  'siret26130008100484': ['<em>Marseille</em>',\n",
       "   '13385 <em>MARSEILLE</em> CEDEX 05'],\n",
       "  'siret26130008100120': ['13274 <em>MARSEILLE</em> CEDEX 09'],\n",
       "  'siret15100002300300': ['13384 <em>MARSEILLE</em> CEDEX 13'],\n",
       "  'siret26130008100393': ['13005 <em>MARSEILLE</em>']},\n",
       " 'nb_matches': {'siret26130008100096': 1,\n",
       "  'siret26130008100153': 1,\n",
       "  'siret78292123300014': 1,\n",
       "  'siret26130008100088': 1,\n",
       "  'siret26130008100138': 1,\n",
       "  'siret26130008100484': 1,\n",
       "  'siret26130008100120': 1,\n",
       "  'siret15100002300300': 1,\n",
       "  'siret26130008100393': 1}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_match_city(\"paoli calmette marseille\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_unstructured(query='', raison_sociale=None, city=None):\n",
    "\n",
    "    logs = \"\"\n",
    "    logs += \"<h1> &#128269; {}</h1>\".format(query)\n",
    "    x = query\n",
    "    if raison_sociale is None:\n",
    "        raison_sociale = x\n",
    "    if city is None:\n",
    "        city = x\n",
    "   \n",
    "    matching_info={}\n",
    "    matching_info['city'] = get_match_city(x)\n",
    "    matching_info['name'] = get_match_name(x)\n",
    "\n",
    "    strategies=[]\n",
    "\n",
    "    strategies.append(\"name;city\")\n",
    "\n",
    "    return match_structured(matching_info, strategies, logs)\n",
    "\n",
    "def match_structured(matching_info, strategies, logs):\n",
    "    \n",
    "    \n",
    "    all_matches = {}\n",
    "    field_matches = {}\n",
    "    min_match_for_field = {}\n",
    "    for f in matching_info:\n",
    "        for match_id in matching_info[f].get('nb_matches', {}):\n",
    "            if match_id not in all_matches:\n",
    "                all_matches[match_id] = 0\n",
    "                field_matches[match_id] = []\n",
    "            all_matches[match_id] += matching_info[f].get('nb_matches', {})[match_id]\n",
    "            if f not in field_matches[match_id]:\n",
    "                field_matches[match_id].append(f)\n",
    "                \n",
    "        min_match_for_field[f] = 1\n",
    "    \n",
    "    relevant_matches = {}\n",
    "    \n",
    "    \n",
    "    final_results = {}\n",
    "    forbidden_id = []\n",
    "    \n",
    "    logs += \"<ol> \"\n",
    "    for strat in strategies:\n",
    "        stop_current_start = False\n",
    "        current_strat_answers = []\n",
    "        strat_fields = strat.split(';')\n",
    "        logs += \"<li>Strategie testée : {}\".format(strat)\n",
    "        \n",
    "        indiv_ids = [matching_info[field]['ids'] for field in strat_fields]\n",
    "        strat_ids = set(indiv_ids[0]).intersection(*indiv_ids)\n",
    "\n",
    "        if len(strat_ids) == 0:\n",
    "            logs += \" &empty; </li>\"\n",
    "            continue\n",
    "        logs += \"</li></br>\"\n",
    "            \n",
    "            \n",
    "        max_number = {}\n",
    "        logs += \"<ol> \"\n",
    "        \n",
    "        potential_sirens = []\n",
    "        \n",
    "        for potential_id in strat_ids:\n",
    "            logs += \" <li> Id potentiel : {}<br/></li>\".format(potential_id)\n",
    "            current_match = {'id': potential_id}\n",
    "            \n",
    "            if 'sire' in potential_id:\n",
    "                potential_sirens.append(potential_id[5:14])\n",
    "            \n",
    "            for field in strat_fields:\n",
    "                current_match[field+'_match'] = 0\n",
    "                #probleme avec les highlights\n",
    "                bbb =  matching_info[field]['nb_matches'][potential_id]\n",
    "                if potential_id in matching_info[field]['nb_matches']:\n",
    "                    current_match[field+'_match'] = matching_info[field]['nb_matches'][potential_id]\n",
    "                    \n",
    "                    current_highlights = matching_info[field]['highlights'][potential_id]\n",
    "                    current_highlights = [e.replace('<em>', '<strong>').replace('</em>', '</strong>') for e in current_highlights]\n",
    "                    logs += \"     - {} {} : {}<br/>\".format(\n",
    "                            matching_info[field]['nb_matches'][potential_id],\n",
    "                            field,\n",
    "                            current_highlights)    \n",
    "          \n",
    "                \n",
    "                if field not in max_number:\n",
    "                    max_number[field] = 0\n",
    "                    #if field == 'name':\n",
    "                    #    max_number[field] = 2\n",
    "\n",
    "                max_number[field] = max(max_number[field], current_match[field+'_match'])\n",
    "\n",
    "            current_strat_answers.append(current_match)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if len(max_number)>0:\n",
    "            logs += \"<li> &#9989; Nombre de match par champ : {}<br/></li>\".format(max_number)\n",
    "            \n",
    "        logs += \"</ol>\" # end of potential ids\n",
    "                \n",
    "        if len(strat_ids) == 0:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        \n",
    "        current_potential_ids = strat_ids\n",
    "        retained_id_for_strat = []\n",
    "        ignored_id = []\n",
    "        logs += \"Parcours des champs de la stratégie :\"\n",
    "        for field in strat_fields:\n",
    "            logs += \"{}...\".format(field)\n",
    "            if field in [\"city\", \"code_fuzzy\"]:\n",
    "                logs += \"(ignoré)...\"\n",
    "                continue\n",
    " \n",
    "            for potential_id in current_potential_ids:\n",
    "                if potential_id in matching_info[field]['nb_matches']:\n",
    "                    if  matching_info[field]['nb_matches'][potential_id] == max_number[field]:\n",
    "                        if max_number[field] >= min_match_for_field[field]:\n",
    "                            retained_id_for_strat.append(potential_id)\n",
    "                        else:\n",
    "                            logs +=\"<br/> &#128584; \"+potential_id+\" ignoré car {} {} est insuffisant ({} attendus au min)\".format(\n",
    "                                max_number[field], field, min_match_for_field[field])\n",
    "                            ignored_id.append(potential_id)\n",
    "                    elif potential_id not in matching_info.get('code', {}).get('ids', []):\n",
    "                        logs += \"<br/> &#10060; {} ajouté à la black-list car seulement {} {} vs le max est {}\".format(\n",
    "                            potential_id,\n",
    "                            matching_info[field]['nb_matches'][potential_id],\n",
    "                            field,\n",
    "                            max_number[field])\n",
    "                        forbidden_id.append(potential_id)\n",
    "            if len(retained_id_for_strat) == 1:\n",
    "                if ('code' in strat_fields) or ('code_digit' in strat_fields) or ('acronym' in strat_fields) or ('code_fuzzy' in strat_fields):\n",
    "                    logs +=\"<br/> &#9209;&#65039; Arrêt au champ \"+field\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "                    #if verbose:\n",
    "                        #print(\"not stopping because strategy has no code or acronym\")\n",
    "                        #print(matching_info.get('name',{}).get('highlights', {}).get(potential_id))\n",
    "            else:\n",
    "                current_potential_ids = retained_id_for_strat\n",
    "                retained_id_for_strat = []\n",
    "        for x in ignored_id:\n",
    "            retained_id_for_strat.remove(x)\n",
    "        final_results[strat] = list(set(retained_id_for_strat))\n",
    "            \n",
    "    #for res in final_results:\n",
    "        if len(final_results[strat]) == 1:\n",
    "            logs += \"<br/> 1&#65039;&#8419; unique match pour cette stratégie : {} \".format(final_results[strat][0])\n",
    "            if final_results[strat][0] in forbidden_id:\n",
    "                logs += \"&#10060; car dans la black-list\"\n",
    "                continue\n",
    "            \n",
    "                \n",
    "            else:\n",
    "                logs += \" &#128076;<br/>\"\n",
    "                logs += \"<h3>{}</h3>\".format(final_results[strat][0])\n",
    "                return {'match': final_results[strat][0], 'logs': logs}\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            potential_sirens = list(set(potential_sirens))\n",
    "            if len(potential_sirens) == 1:\n",
    "                logs += \"<br/> all potential match have the same siren \" + potential_sirens[0]\n",
    "                return {'match': \"siren\"+potential_sirens[0], 'logs': logs}\n",
    "                \n",
    "    \n",
    "    return {'match': None, 'logs': logs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'match': 'siren263100125',\n",
       " 'logs': \"<h1> &#128269; chu toulouse france</h1><ol> <li>Strategie testée : name;city</li></br><ol>  <li> Id potentiel : siret26310012500065<br/></li>     - 1 name : ['HOPITAL LA GRAVE <strong>CHU</strong> TLSE', 'HOPITAL LA GRAVE <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500628<br/></li>     - 1 name : ['ONCOPOLE <strong>CHU</strong> TOULOUSE', 'ONCOPOLE <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500511<br/></li>     - 1 name : ['HOPITAUX MERE & ENFANTS SITE VIGUIER <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500057<br/></li>     - 1 name : ['HOPITAL DE RANGUEIL <strong>CHU</strong> TOULOUSE', 'HOPITAL DE RANGUEIL <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['<strong>Toulouse</strong>', '31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500594<br/></li>     - 1 name : ['HOPITAL GARONNE <strong>CHU</strong> TOULOUSE', 'HOPITAL GARONNE <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500016<br/></li>     - 1 name : ['HOTEL DIEU ST JACQUES <strong>CHU</strong> TOULOUSE', 'HOTEL DIEU SAINT JACQUES <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['<strong>Toulouse</strong>', '31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500529<br/></li>     - 1 name : ['HOPITAL LARREY <strong>CHU</strong> TLSE', 'HOPITAL LARREY <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500040<br/></li>     - 1 name : ['HOPITAL PURPAN <strong>CHU</strong> TLSE', 'HOPITAL PURPAN <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['<strong>Toulouse</strong>', '31059 <strong>TOULOUSE</strong> CEDEX 9']<br/> <li> Id potentiel : siret26310012500180<br/></li>     - 1 name : ['CTRE CASSELARDIT VILLA ANCELY <strong>CHU</strong> TLSE', 'CENTRE DE CASSELARDIT VILLA ANCELY <strong>CHU</strong> TOULOUSE']<br/>     - 1 city : ['<strong>Toulouse</strong>', '31059 <strong>TOULOUSE</strong> CEDEX 9']<br/><li> &#9989; Nombre de match par champ : {'name': 1, 'city': 1}<br/></li></ol>Parcours des champs de la stratégie :name...city...(ignoré)...<br/> all potential match have the same siren 263100125\"}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_unstructured(\"chu toulouse france\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_unstructured(\"CHU Rangueil, Toulouse, France.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_match_city(\"CHU Rangueil, Toulouse, France.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_match_name(\"Rangueil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=\"Service de Réanimation Néonatale, Centre Hospitalier Universitaire Sud-Réunion, Saint-Pierre, France.\"\n",
    "x=\"Service de Psychiatrie et de Psychologie Médicale, Centre Expert Dépression Résistante FondaMental, CHU Toulouse, Hospital Purpan, ToNIC, Toulouse NeuroImaging Center, Université de Toulouse, Inserm, UPS, Toulouse, France. Electronic address: antoineyrondi@gmail.com.\"\n",
    "match_unstructured(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_unstructured(\"Centre Hospitalier Universitaire (CHU) de Bordeaux, 33000 Bordeaux, France.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(\"http://localhost:9200/index-finess/_analyze\", json={\n",
    "              \"analyzer\" : \"analyzer_name\",\n",
    "              \"text\" : \"Rangueil\"\n",
    "            }).json()\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in finess:\n",
    "    if e.get('Numéro de SIRET siret') == \"26310012500057\":\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Numéro de SIRET siret'] == 26310012500057]['Numéro FINESS ET nofinesset'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
